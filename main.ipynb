{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.94 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.88  Python-3.11.11 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce GTX 1660 Ti, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=Dataset/Pascal_VOC/data.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=320, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train3\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to 'C:\\Users\\edvar\\AppData\\Roaming\\Ultralytics\\Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755k/755k [00:00<00:00, 1.41MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=20\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    755212  ultralytics.nn.modules.head.Detect           [20, [64, 128, 256]]          \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary: 129 layers, 3,014,748 parameters, 3,014,732 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1660 Ti GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\edvar\\Documents\\Pessoal\\tcc\\Dataset\\Pascal_VOC\\labels\\train... 5717 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5717/5717 [00:13<00:00, 422.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\edvar\\Documents\\Pessoal\\tcc\\Dataset\\Pascal_VOC\\labels\\train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\edvar\\Documents\\Pessoal\\tcc\\Dataset\\Pascal_VOC\\labels\\val... 5823 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5823/5823 [00:14<00:00, 398.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\edvar\\Documents\\Pessoal\\tcc\\Dataset\\Pascal_VOC\\labels\\val.cache\n",
      "Plotting labels to runs\\detect\\train3\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000417, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train3\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50      1.01G      1.146      3.055       1.24         39        320: 100%|██████████| 358/358 [00:48<00:00,  7.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 182/182 [00:41<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5823      13841      0.638      0.544      0.579      0.411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50      1.46G      1.167      1.923      1.268         23        320: 100%|██████████| 358/358 [00:50<00:00,  7.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 182/182 [01:18<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5823      13841      0.654      0.528      0.575      0.397\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50      1.46G      1.181      1.824      1.281         27        320: 100%|██████████| 358/358 [01:20<00:00,  4.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 182/182 [00:49<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5823      13841      0.599      0.514      0.539      0.362\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50      1.46G      1.164      1.764      1.277         26        320: 100%|██████████| 358/358 [00:56<00:00,  6.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 182/182 [00:46<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5823      13841      0.623      0.526      0.552      0.376\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50      1.46G      1.142      1.691      1.263         28        320: 100%|██████████| 358/358 [00:46<00:00,  7.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 182/182 [00:42<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5823      13841       0.61      0.542      0.565      0.383\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50      1.46G       1.14      1.656      1.257         23        320: 100%|██████████| 358/358 [00:46<00:00,  7.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 182/182 [00:41<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5823      13841      0.643      0.546      0.577      0.386\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50      1.46G      1.122      1.609      1.244         22        320: 100%|██████████| 358/358 [00:45<00:00,  7.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 182/182 [00:42<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5823      13841       0.64      0.539      0.585      0.402\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50      1.46G      1.116       1.56      1.239         38        320: 100%|██████████| 358/358 [00:45<00:00,  7.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 182/182 [00:41<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5823      13841      0.665      0.534      0.586      0.404\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50      1.46G      1.099      1.541      1.228         40        320: 100%|██████████| 358/358 [00:44<00:00,  7.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 182/182 [00:42<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5823      13841      0.689      0.533      0.594       0.41\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50      1.46G      1.097       1.51      1.233         24        320: 100%|██████████| 358/358 [00:45<00:00,  7.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 182/182 [00:42<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5823      13841      0.672      0.556      0.605      0.416\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50      1.46G      1.086      1.488      1.226         21        320: 100%|██████████| 358/358 [00:47<00:00,  7.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 182/182 [00:46<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5823      13841       0.68      0.565      0.617      0.427\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50      1.46G      1.076      1.458      1.223         27        320: 100%|██████████| 358/358 [00:47<00:00,  7.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 182/182 [00:41<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5823      13841      0.688      0.563      0.616      0.426\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50      1.46G      1.069      1.416      1.212         20        320: 100%|██████████| 358/358 [00:49<00:00,  7.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 182/182 [00:41<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5823      13841      0.701      0.574      0.632      0.441\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50      1.46G      1.049      1.396      1.203         34        320: 100%|██████████| 358/358 [00:44<00:00,  8.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 182/182 [00:41<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5823      13841      0.701      0.555      0.618      0.433\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50      1.46G      1.042      1.372      1.197         30        320: 100%|██████████| 358/358 [00:47<00:00,  7.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 182/182 [00:49<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5823      13841      0.697      0.574      0.637      0.442\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50      1.46G      1.041      1.351      1.198         19        320: 100%|██████████| 358/358 [00:52<00:00,  6.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  80%|████████  | 146/182 [00:37<00:09,  3.88it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     14\u001b[39m     freeze_support()\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      7\u001b[39m model = YOLO(\u001b[33m'\u001b[39m\u001b[33myolov8n.pt\u001b[39m\u001b[33m'\u001b[39m) \n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# yolo.train(data='Dataset/Pascal_VOC/data.yaml', epochs=50, batch_size=16, imgsz=320)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mDataset/Pascal_VOC/data.yaml\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m320\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\edvar\\miniconda3\\envs\\nn\\Lib\\site-packages\\ultralytics\\engine\\model.py:810\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, trainer, **kwargs)\u001b[39m\n\u001b[32m    807\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.trainer.model\n\u001b[32m    809\u001b[39m \u001b[38;5;28mself\u001b[39m.trainer.hub_session = \u001b[38;5;28mself\u001b[39m.session  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m810\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    811\u001b[39m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[32m    812\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {-\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m}:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\edvar\\miniconda3\\envs\\nn\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:208\u001b[39m, in \u001b[36mBaseTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    205\u001b[39m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\edvar\\miniconda3\\envs\\nn\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:433\u001b[39m, in \u001b[36mBaseTrainer._do_train\u001b[39m\u001b[34m(self, world_size)\u001b[39m\n\u001b[32m    431\u001b[39m \u001b[38;5;66;03m# Validation\u001b[39;00m\n\u001b[32m    432\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.val \u001b[38;5;129;01mor\u001b[39;00m final_epoch \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stopper.possible_stop \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop:\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m     \u001b[38;5;28mself\u001b[39m.metrics, \u001b[38;5;28mself\u001b[39m.fitness = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[38;5;28mself\u001b[39m.save_metrics(metrics={**\u001b[38;5;28mself\u001b[39m.label_loss_items(\u001b[38;5;28mself\u001b[39m.tloss), **\u001b[38;5;28mself\u001b[39m.metrics, **\u001b[38;5;28mself\u001b[39m.lr})\n\u001b[32m    435\u001b[39m \u001b[38;5;28mself\u001b[39m.stop |= \u001b[38;5;28mself\u001b[39m.stopper(epoch + \u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.fitness) \u001b[38;5;129;01mor\u001b[39;00m final_epoch\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\edvar\\miniconda3\\envs\\nn\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:617\u001b[39m, in \u001b[36mBaseTrainer.validate\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    611\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalidate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    612\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    613\u001b[39m \u001b[33;03m    Runs validation on test set using self.validator.\u001b[39;00m\n\u001b[32m    614\u001b[39m \n\u001b[32m    615\u001b[39m \u001b[33;03m    The returned dict is expected to contain \"fitness\" key.\u001b[39;00m\n\u001b[32m    616\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m617\u001b[39m     metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    618\u001b[39m     fitness = metrics.pop(\u001b[33m\"\u001b[39m\u001b[33mfitness\u001b[39m\u001b[33m\"\u001b[39m, -\u001b[38;5;28mself\u001b[39m.loss.detach().cpu().numpy())  \u001b[38;5;66;03m# use loss as fitness measure if not found\u001b[39;00m\n\u001b[32m    619\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.best_fitness \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.best_fitness < fitness:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\edvar\\miniconda3\\envs\\nn\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\edvar\\miniconda3\\envs\\nn\\Lib\\site-packages\\ultralytics\\engine\\validator.py:193\u001b[39m, in \u001b[36mBaseValidator.__call__\u001b[39m\u001b[34m(self, trainer, model)\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m dt[\u001b[32m3\u001b[39m]:\n\u001b[32m    191\u001b[39m     preds = \u001b[38;5;28mself\u001b[39m.postprocess(preds)\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mupdate_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.plots \u001b[38;5;129;01mand\u001b[39;00m batch_i < \u001b[32m3\u001b[39m:\n\u001b[32m    195\u001b[39m     \u001b[38;5;28mself\u001b[39m.plot_val_samples(batch, batch_i)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\edvar\\miniconda3\\envs\\nn\\Lib\\site-packages\\ultralytics\\models\\yolo\\detect\\val.py:161\u001b[39m, in \u001b[36mDetectionValidator.update_metrics\u001b[39m\u001b[34m(self, preds, batch)\u001b[39m\n\u001b[32m    159\u001b[39m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nl:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     stat[\u001b[33m\"\u001b[39m\u001b[33mtp\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.plots:\n\u001b[32m    163\u001b[39m     \u001b[38;5;28mself\u001b[39m.confusion_matrix.process_batch(predn, bbox, \u001b[38;5;28mcls\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\edvar\\miniconda3\\envs\\nn\\Lib\\site-packages\\ultralytics\\models\\yolo\\detect\\val.py:231\u001b[39m, in \u001b[36mDetectionValidator._process_batch\u001b[39m\u001b[34m(self, detections, gt_bboxes, gt_cls)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_process_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m, detections, gt_bboxes, gt_cls):\n\u001b[32m    214\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[33;03m    Return correct prediction matrix.\u001b[39;00m\n\u001b[32m    216\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    229\u001b[39m \u001b[33;03m        intermediate representation used for evaluating predictions against ground truth.\u001b[39;00m\n\u001b[32m    230\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m     iou = \u001b[43mbox_iou\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgt_bboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetections\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    232\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.match_predictions(detections[:, \u001b[32m5\u001b[39m], gt_cls, iou)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\edvar\\miniconda3\\envs\\nn\\Lib\\site-packages\\ultralytics\\utils\\metrics.py:68\u001b[39m, in \u001b[36mbox_iou\u001b[39m\u001b[34m(box1, box2, eps)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# NOTE: Need .float() to get accurate iou values\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# inter(N,M) = (rb(N,M,2) - lt(N,M,2)).clamp(0).prod(2)\u001b[39;00m\n\u001b[32m     67\u001b[39m (a1, a2), (b1, b2) = box1.float().unsqueeze(\u001b[32m1\u001b[39m).chunk(\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m), box2.float().unsqueeze(\u001b[32m0\u001b[39m).chunk(\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m inter = \u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclamp_\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m.prod(\u001b[32m2\u001b[39m)\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# IoU = inter / (area1 + area2 - inter)\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m inter / ((a2 - a1).prod(\u001b[32m2\u001b[39m) + (b2 - b1).prod(\u001b[32m2\u001b[39m) - inter + eps)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Treinar yolo\n",
    "from ultralytics import YOLO\n",
    "from multiprocessing import freeze_support\n",
    "\n",
    "def main():\n",
    "\n",
    "    model = YOLO('yolov8n.pt') \n",
    "\n",
    "    # yolo.train(data='Dataset/Pascal_VOC/data.yaml', epochs=50, batch_size=16, imgsz=320)\n",
    "\n",
    "    model.train(data='Dataset/Pascal_VOC/data.yaml', epochs=50, batch=16, imgsz=320)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    freeze_support()\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
