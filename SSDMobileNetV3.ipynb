{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.6.0-cp311-cp311-win_amd64.whl.metadata (28 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.21.0-cp311-cp311-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting onnx\n",
      "  Using cached onnx-1.17.0-cp311-cp311-win_amd64.whl.metadata (16 kB)\n",
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.21.0-cp311-cp311-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.1-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\edvar\\appdata\\roaming\\python\\python311\\site-packages (from torch) (4.12.2)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting numpy (from torchvision)\n",
      "  Downloading numpy-2.2.3-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Using cached pillow-11.1.0-cp311-cp311-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting protobuf>=3.20.2 (from onnx)\n",
      "  Downloading protobuf-6.30.0-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting coloredlogs (from onnxruntime)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: packaging in c:\\users\\edvar\\appdata\\roaming\\python\\python311\\site-packages (from onnxruntime) (24.2)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.1-cp311-cp311-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.56.0-cp311-cp311-win_amd64.whl.metadata (103 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.8-cp311-cp311-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\edvar\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\edvar\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime)\n",
      "  Downloading pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading torch-2.6.0-cp311-cp311-win_amd64.whl (204.2 MB)\n",
      "   ---------------------------------------- 0.0/204.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/204.2 MB 10.5 MB/s eta 0:00:20\n",
      "    --------------------------------------- 4.2/204.2 MB 11.0 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 6.6/204.2 MB 11.2 MB/s eta 0:00:18\n",
      "   - -------------------------------------- 8.9/204.2 MB 11.1 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 11.3/204.2 MB 11.2 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 13.6/204.2 MB 11.3 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 16.3/204.2 MB 11.4 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 18.6/204.2 MB 11.4 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 21.0/204.2 MB 11.4 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 23.6/204.2 MB 11.5 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 26.0/204.2 MB 11.6 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 28.3/204.2 MB 11.5 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 30.7/204.2 MB 11.5 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 33.3/204.2 MB 11.6 MB/s eta 0:00:15\n",
      "   ------ --------------------------------- 35.7/204.2 MB 11.5 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 38.0/204.2 MB 11.5 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 40.4/204.2 MB 11.5 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 43.0/204.2 MB 11.5 MB/s eta 0:00:14\n",
      "   -------- ------------------------------- 45.6/204.2 MB 11.6 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 48.0/204.2 MB 11.6 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 50.3/204.2 MB 11.5 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 53.0/204.2 MB 11.5 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 55.3/204.2 MB 11.6 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 57.9/204.2 MB 11.6 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 60.6/204.2 MB 11.6 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 62.9/204.2 MB 11.6 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 65.3/204.2 MB 11.6 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 67.6/204.2 MB 11.6 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 70.0/204.2 MB 11.6 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 72.4/204.2 MB 11.6 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 74.2/204.2 MB 11.6 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 76.5/204.2 MB 11.5 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 78.9/204.2 MB 11.5 MB/s eta 0:00:11\n",
      "   --------------- ------------------------ 81.0/204.2 MB 11.5 MB/s eta 0:00:11\n",
      "   ---------------- ----------------------- 83.1/204.2 MB 11.4 MB/s eta 0:00:11\n",
      "   ---------------- ----------------------- 85.2/204.2 MB 11.4 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 87.6/204.2 MB 11.4 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 89.9/204.2 MB 11.4 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 92.3/204.2 MB 11.4 MB/s eta 0:00:10\n",
      "   ------------------ --------------------- 94.4/204.2 MB 11.4 MB/s eta 0:00:10\n",
      "   ------------------ --------------------- 96.7/204.2 MB 11.4 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 99.1/204.2 MB 11.4 MB/s eta 0:00:10\n",
      "   ------------------- ------------------- 101.7/204.2 MB 11.4 MB/s eta 0:00:09\n",
      "   ------------------- ------------------- 104.1/204.2 MB 11.4 MB/s eta 0:00:09\n",
      "   -------------------- ------------------ 106.7/204.2 MB 11.4 MB/s eta 0:00:09\n",
      "   -------------------- ------------------ 109.1/204.2 MB 11.4 MB/s eta 0:00:09\n",
      "   --------------------- ----------------- 111.4/204.2 MB 11.4 MB/s eta 0:00:09\n",
      "   --------------------- ----------------- 113.8/204.2 MB 11.4 MB/s eta 0:00:08\n",
      "   ---------------------- ---------------- 116.1/204.2 MB 11.4 MB/s eta 0:00:08\n",
      "   ---------------------- ---------------- 118.5/204.2 MB 11.4 MB/s eta 0:00:08\n",
      "   ----------------------- --------------- 120.8/204.2 MB 11.4 MB/s eta 0:00:08\n",
      "   ----------------------- --------------- 123.2/204.2 MB 11.4 MB/s eta 0:00:08\n",
      "   ----------------------- --------------- 125.6/204.2 MB 11.4 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 127.9/204.2 MB 11.4 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 130.5/204.2 MB 11.4 MB/s eta 0:00:07\n",
      "   ------------------------- ------------- 133.2/204.2 MB 11.4 MB/s eta 0:00:07\n",
      "   ------------------------- ------------- 135.3/204.2 MB 11.4 MB/s eta 0:00:07\n",
      "   -------------------------- ------------ 137.6/204.2 MB 11.4 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 140.2/204.2 MB 11.4 MB/s eta 0:00:06\n",
      "   --------------------------- ----------- 142.3/204.2 MB 11.4 MB/s eta 0:00:06\n",
      "   --------------------------- ----------- 145.0/204.2 MB 11.4 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 147.3/204.2 MB 11.4 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 149.9/204.2 MB 11.4 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 152.3/204.2 MB 11.4 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 154.9/204.2 MB 11.4 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 157.5/204.2 MB 11.4 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 159.9/204.2 MB 11.4 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 162.5/204.2 MB 11.4 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 165.2/204.2 MB 11.5 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 167.5/204.2 MB 11.4 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 169.9/204.2 MB 11.5 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 172.5/204.2 MB 11.5 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 175.1/204.2 MB 11.5 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 177.5/204.2 MB 11.5 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 180.1/204.2 MB 11.5 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 182.7/204.2 MB 11.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 185.1/204.2 MB 11.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 187.7/204.2 MB 11.5 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 190.3/204.2 MB 11.5 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 192.7/204.2 MB 11.5 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 195.3/204.2 MB 11.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 197.7/204.2 MB 11.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  200.3/204.2 MB 11.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.6/204.2 MB 11.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.9/204.2 MB 11.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.9/204.2 MB 11.5 MB/s eta 0:00:01\n",
      "   --------------------------------------- 204.2/204.2 MB 11.2 MB/s eta 0:00:00\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 2.4/6.2 MB 12.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.7/6.2 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 11.5 MB/s eta 0:00:00\n",
      "Downloading torchvision-0.21.0-cp311-cp311-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 10.4 MB/s eta 0:00:00\n",
      "Using cached onnx-1.17.0-cp311-cp311-win_amd64.whl (14.5 MB)\n",
      "Downloading onnxruntime-1.21.0-cp311-cp311-win_amd64.whl (11.8 MB)\n",
      "   ---------------------------------------- 0.0/11.8 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 2.4/11.8 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 5.0/11.8 MB 11.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.3/11.8 MB 11.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.7/11.8 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.8/11.8 MB 11.5 MB/s eta 0:00:00\n",
      "Using cached matplotlib-3.10.1-cp311-cp311-win_amd64.whl (8.1 MB)\n",
      "Using cached contourpy-1.3.1-cp311-cp311-win_amd64.whl (219 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.56.0-cp311-cp311-win_amd64.whl (2.2 MB)\n",
      "Using cached kiwisolver-1.4.8-cp311-cp311-win_amd64.whl (71 kB)\n",
      "Downloading numpy-2.2.3-cp311-cp311-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 2.4/12.9 MB 11.2 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 5.0/12.9 MB 11.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.6/12.9 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 10.0/12.9 MB 11.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.3/12.9 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 11.4 MB/s eta 0:00:00\n",
      "Using cached pillow-11.1.0-cp311-cp311-win_amd64.whl (2.6 MB)\n",
      "Downloading protobuf-6.30.0-cp310-abi3-win_amd64.whl (430 kB)\n",
      "Using cached pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 9.4 MB/s eta 0:00:00\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl (15 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 536.2/536.2 kB 17.1 MB/s eta 0:00:00\n",
      "Downloading pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: mpmath, flatbuffers, sympy, pyreadline3, pyparsing, protobuf, pillow, numpy, networkx, MarkupSafe, kiwisolver, fsspec, fonttools, filelock, cycler, onnx, jinja2, humanfriendly, contourpy, torch, matplotlib, coloredlogs, torchvision, onnxruntime\n",
      "Successfully installed MarkupSafe-3.0.2 coloredlogs-15.0.1 contourpy-1.3.1 cycler-0.12.1 filelock-3.17.0 flatbuffers-25.2.10 fonttools-4.56.0 fsspec-2025.3.0 humanfriendly-10.0 jinja2-3.1.6 kiwisolver-1.4.8 matplotlib-3.10.1 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.3 onnx-1.17.0 onnxruntime-1.21.0 pillow-11.1.0 protobuf-6.30.0 pyparsing-3.2.1 pyreadline3-3.5.4 sympy-1.13.1 torch-2.6.0 torchvision-0.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision onnx onnxruntime matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão PyTorch: 2.5.1+cu121\n",
      "Versão TorchVision: 0.20.1+cu121\n",
      "Usando dispositivo: cuda\n",
      "Versão PyTorch: 2.5.1+cu121\n",
      "Versão torchvision: 0.20.1+cu121\n",
      "Preparando o dataset Pascal VOC 2012 já baixado...\n",
      "Tamanho do dataset de treino: 5717\n",
      "Tamanho do dataset de validação: 5823\n",
      "Criando modelo SSDLite320 com MobileNetV3...\n",
      "Adaptando modelo para classes VOC...\n",
      "Erro ao acessar 'in_channels'. Tentando abordagem alternativa...\n",
      "Explorando estrutura do modelo:\n",
      "Head: SSDLiteHead\n",
      "Classification head: SSDLiteClassificationHead\n",
      "Atributos da cabeça de classificação: ['T_destination', 'add_module', 'apply', 'bfloat16', 'buffers', 'call_super_init', 'children', 'compile', 'cpu', 'cuda', 'double', 'dump_patches', 'eval', 'extra_repr', 'float', 'forward', 'get_buffer', 'get_extra_state', 'get_parameter', 'get_submodule', 'half', 'ipu', 'load_state_dict', 'module_list', 'modules', 'mtia', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'num_columns', 'parameters', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_load_state_dict_pre_hook', 'register_module', 'register_parameter', 'register_state_dict_post_hook', 'register_state_dict_pre_hook', 'requires_grad_', 'set_extra_state', 'set_submodule', 'share_memory', 'state_dict', 'to', 'to_empty', 'train', 'training', 'type', 'xpu', 'zero_grad']\n",
      "Iniciando treinamento...\n",
      "\n",
      "Época 1/50\n",
      "  Batch 20/358, Perda: 10.4989\n",
      "  Batch 40/358, Perda: 9.0455\n",
      "  Batch 60/358, Perda: 7.9395\n",
      "  Batch 80/358, Perda: 6.1874\n",
      "  Batch 100/358, Perda: 7.8657\n",
      "  Batch 120/358, Perda: 6.4516\n",
      "  Batch 140/358, Perda: 6.5500\n",
      "  Batch 160/358, Perda: 7.1127\n",
      "  Batch 180/358, Perda: 6.6312\n",
      "  Batch 200/358, Perda: 6.6228\n",
      "  Batch 220/358, Perda: 6.4200\n",
      "  Batch 240/358, Perda: 5.6783\n",
      "  Batch 260/358, Perda: 6.9553\n",
      "  Batch 280/358, Perda: 6.1378\n",
      "  Batch 300/358, Perda: 5.5772\n",
      "  Batch 320/358, Perda: 5.8898\n",
      "  Batch 340/358, Perda: 5.4379\n",
      "  Perda de treinamento: 7.0909, Perda de validação: 5.6547\n",
      "  Melhor modelo salvo (perda de validação: 5.6547)\n",
      "\n",
      "Época 2/50\n",
      "  Batch 20/358, Perda: 4.8966\n",
      "  Batch 40/358, Perda: 5.6973\n",
      "  Batch 60/358, Perda: 4.7563\n",
      "  Batch 80/358, Perda: 5.8113\n",
      "  Batch 100/358, Perda: 4.8498\n",
      "  Batch 120/358, Perda: 5.0716\n",
      "  Batch 140/358, Perda: 5.7969\n",
      "  Batch 160/358, Perda: 5.1754\n",
      "  Batch 180/358, Perda: 4.7534\n",
      "  Batch 200/358, Perda: 5.4885\n",
      "  Batch 220/358, Perda: 4.6239\n",
      "  Batch 240/358, Perda: 4.7564\n",
      "  Batch 260/358, Perda: 5.4138\n",
      "  Batch 280/358, Perda: 4.9083\n",
      "  Batch 300/358, Perda: 4.5810\n",
      "  Batch 320/358, Perda: 4.9060\n",
      "  Batch 340/358, Perda: 5.4041\n",
      "  Perda de treinamento: 5.1895, Perda de validação: 5.1037\n",
      "  Melhor modelo salvo (perda de validação: 5.1037)\n",
      "\n",
      "Época 3/50\n",
      "  Batch 20/358, Perda: 4.2688\n",
      "  Batch 40/358, Perda: 4.3411\n",
      "  Batch 60/358, Perda: 5.1479\n",
      "  Batch 80/358, Perda: 4.9060\n",
      "  Batch 100/358, Perda: 4.8032\n",
      "  Batch 120/358, Perda: 4.8433\n",
      "  Batch 140/358, Perda: 4.7897\n",
      "  Batch 160/358, Perda: 5.3618\n",
      "  Batch 180/358, Perda: 4.8054\n",
      "  Batch 200/358, Perda: 4.1386\n",
      "  Batch 220/358, Perda: 4.8784\n",
      "  Batch 240/358, Perda: 3.9346\n",
      "  Batch 260/358, Perda: 4.5894\n",
      "  Batch 280/358, Perda: 4.5824\n",
      "  Batch 300/358, Perda: 4.1105\n",
      "  Batch 320/358, Perda: 4.6013\n",
      "  Batch 340/358, Perda: 4.3016\n",
      "  Perda de treinamento: 4.6957, Perda de validação: 4.8983\n",
      "  Melhor modelo salvo (perda de validação: 4.8983)\n",
      "\n",
      "Época 4/50\n",
      "  Batch 20/358, Perda: 4.0123\n",
      "  Batch 40/358, Perda: 3.9150\n",
      "  Batch 60/358, Perda: 4.0678\n",
      "  Batch 80/358, Perda: 3.9807\n",
      "  Batch 100/358, Perda: 4.3311\n",
      "  Batch 120/358, Perda: 5.0129\n",
      "  Batch 140/358, Perda: 4.4521\n",
      "  Batch 160/358, Perda: 3.8510\n",
      "  Batch 180/358, Perda: 4.2991\n",
      "  Batch 200/358, Perda: 5.2293\n",
      "  Batch 220/358, Perda: 4.6754\n",
      "  Batch 240/358, Perda: 3.5601\n",
      "  Batch 260/358, Perda: 4.2414\n",
      "  Batch 280/358, Perda: 4.1730\n",
      "  Batch 300/358, Perda: 3.9736\n",
      "  Batch 320/358, Perda: 4.4115\n",
      "  Batch 340/358, Perda: 4.4098\n",
      "  Perda de treinamento: 4.3591, Perda de validação: 4.8340\n",
      "  Melhor modelo salvo (perda de validação: 4.8340)\n",
      "\n",
      "Época 5/50\n",
      "  Batch 20/358, Perda: 5.3106\n",
      "  Batch 40/358, Perda: 4.6628\n",
      "  Batch 60/358, Perda: 4.3446\n",
      "  Batch 80/358, Perda: 4.2284\n",
      "  Batch 100/358, Perda: 4.1842\n",
      "  Batch 120/358, Perda: 4.7622\n",
      "  Batch 140/358, Perda: 4.3054\n",
      "  Batch 160/358, Perda: 3.6934\n",
      "  Batch 180/358, Perda: 4.5968\n",
      "  Batch 200/358, Perda: 4.2980\n",
      "  Batch 220/358, Perda: 4.8647\n",
      "  Batch 240/358, Perda: 4.7615\n",
      "  Batch 260/358, Perda: 4.3268\n",
      "  Batch 280/358, Perda: 4.5630\n",
      "  Batch 300/358, Perda: 4.7231\n",
      "  Batch 320/358, Perda: 5.2594\n",
      "  Batch 340/358, Perda: 4.4769\n",
      "  Perda de treinamento: 4.3096, Perda de validação: 4.8172\n",
      "  Melhor modelo salvo (perda de validação: 4.8172)\n",
      "\n",
      "Época 6/50\n",
      "  Batch 20/358, Perda: 4.2937\n",
      "  Batch 40/358, Perda: 4.1389\n",
      "  Batch 60/358, Perda: 3.4802\n",
      "  Batch 80/358, Perda: 4.2170\n",
      "  Batch 100/358, Perda: 4.1528\n",
      "  Batch 120/358, Perda: 4.7229\n",
      "  Batch 140/358, Perda: 3.7614\n",
      "  Batch 160/358, Perda: 4.0320\n",
      "  Batch 180/358, Perda: 4.0918\n",
      "  Batch 200/358, Perda: 4.3669\n",
      "  Batch 220/358, Perda: 3.4874\n",
      "  Batch 240/358, Perda: 3.7947\n",
      "  Batch 260/358, Perda: 4.0261\n",
      "  Batch 280/358, Perda: 4.1745\n",
      "  Batch 300/358, Perda: 4.3563\n",
      "  Batch 320/358, Perda: 3.2326\n",
      "  Batch 340/358, Perda: 4.1842\n",
      "  Perda de treinamento: 4.2570, Perda de validação: 4.8073\n",
      "  Melhor modelo salvo (perda de validação: 4.8073)\n",
      "\n",
      "Época 7/50\n",
      "  Batch 20/358, Perda: 4.4830\n",
      "  Batch 40/358, Perda: 4.4221\n",
      "  Batch 60/358, Perda: 4.2510\n",
      "  Batch 80/358, Perda: 3.9391\n",
      "  Batch 100/358, Perda: 4.3048\n",
      "  Batch 120/358, Perda: 3.8873\n",
      "  Batch 140/358, Perda: 4.4374\n",
      "  Batch 160/358, Perda: 5.0099\n",
      "  Batch 180/358, Perda: 4.6909\n",
      "  Batch 200/358, Perda: 3.7319\n",
      "  Batch 220/358, Perda: 4.7306\n",
      "  Batch 240/358, Perda: 4.2023\n",
      "  Batch 260/358, Perda: 4.5689\n",
      "  Batch 280/358, Perda: 3.5422\n",
      "  Batch 300/358, Perda: 4.0503\n",
      "  Batch 320/358, Perda: 4.0051\n",
      "  Batch 340/358, Perda: 4.3264\n",
      "  Perda de treinamento: 4.2320, Perda de validação: 4.8047\n",
      "  Melhor modelo salvo (perda de validação: 4.8047)\n",
      "\n",
      "Época 8/50\n",
      "  Batch 20/358, Perda: 4.9571\n",
      "  Batch 40/358, Perda: 4.5508\n",
      "  Batch 60/358, Perda: 4.6333\n",
      "  Batch 80/358, Perda: 4.3126\n",
      "  Batch 100/358, Perda: 4.1610\n",
      "  Batch 120/358, Perda: 4.6512\n",
      "  Batch 140/358, Perda: 4.0890\n",
      "  Batch 160/358, Perda: 4.3109\n",
      "  Batch 180/358, Perda: 3.8755\n",
      "  Batch 200/358, Perda: 4.0813\n",
      "  Batch 220/358, Perda: 5.3522\n",
      "  Batch 240/358, Perda: 3.9282\n",
      "  Batch 260/358, Perda: 3.5080\n",
      "  Batch 280/358, Perda: 4.3944\n",
      "  Batch 300/358, Perda: 4.0268\n",
      "  Batch 320/358, Perda: 4.1299\n",
      "  Batch 340/358, Perda: 4.6869\n",
      "  Perda de treinamento: 4.2191, Perda de validação: 4.8032\n",
      "  Melhor modelo salvo (perda de validação: 4.8032)\n",
      "\n",
      "Época 9/50\n",
      "  Batch 20/358, Perda: 4.0147\n",
      "  Batch 40/358, Perda: 4.2577\n",
      "  Batch 60/358, Perda: 4.4776\n",
      "  Batch 80/358, Perda: 4.8427\n",
      "  Batch 100/358, Perda: 4.6589\n",
      "  Batch 120/358, Perda: 3.7527\n",
      "  Batch 140/358, Perda: 3.8709\n",
      "  Batch 160/358, Perda: 4.2035\n",
      "  Batch 180/358, Perda: 3.4756\n",
      "  Batch 200/358, Perda: 3.8801\n",
      "  Batch 220/358, Perda: 4.1923\n",
      "  Batch 240/358, Perda: 4.1485\n",
      "  Batch 260/358, Perda: 4.7087\n",
      "  Batch 280/358, Perda: 4.1565\n",
      "  Batch 300/358, Perda: 4.5656\n",
      "  Batch 320/358, Perda: 4.3566\n",
      "  Batch 340/358, Perda: 4.5186\n",
      "  Perda de treinamento: 4.2161, Perda de validação: 4.8021\n",
      "  Melhor modelo salvo (perda de validação: 4.8021)\n",
      "\n",
      "Época 10/50\n",
      "  Batch 20/358, Perda: 3.8219\n",
      "  Batch 40/358, Perda: 3.9024\n",
      "  Batch 60/358, Perda: 5.0298\n",
      "  Batch 80/358, Perda: 4.2321\n",
      "  Batch 100/358, Perda: 4.1684\n",
      "  Batch 120/358, Perda: 4.1556\n",
      "  Batch 140/358, Perda: 4.1737\n",
      "  Batch 160/358, Perda: 4.4940\n",
      "  Batch 180/358, Perda: 4.1263\n",
      "  Batch 200/358, Perda: 4.2015\n",
      "  Batch 220/358, Perda: 4.7401\n",
      "  Batch 240/358, Perda: 4.0108\n",
      "  Batch 260/358, Perda: 3.8175\n",
      "  Batch 280/358, Perda: 4.7318\n",
      "  Batch 300/358, Perda: 4.5845\n",
      "  Batch 320/358, Perda: 4.9610\n",
      "  Batch 340/358, Perda: 4.7777\n",
      "  Perda de treinamento: 4.2102, Perda de validação: 4.8020\n",
      "  Melhor modelo salvo (perda de validação: 4.8020)\n",
      "\n",
      "Época 11/50\n",
      "  Batch 20/358, Perda: 4.1378\n",
      "  Batch 40/358, Perda: 3.6790\n",
      "  Batch 60/358, Perda: 3.7674\n",
      "  Batch 80/358, Perda: 4.8267\n",
      "  Batch 100/358, Perda: 3.9710\n",
      "  Batch 120/358, Perda: 4.4254\n",
      "  Batch 140/358, Perda: 4.5319\n",
      "  Batch 160/358, Perda: 4.4106\n",
      "  Batch 180/358, Perda: 3.9153\n",
      "  Batch 200/358, Perda: 2.8403\n",
      "  Batch 220/358, Perda: 4.8469\n",
      "  Batch 240/358, Perda: 4.2572\n",
      "  Batch 260/358, Perda: 3.9835\n",
      "  Batch 280/358, Perda: 3.1455\n",
      "  Batch 300/358, Perda: 4.6136\n",
      "  Batch 320/358, Perda: 3.9131\n",
      "  Batch 340/358, Perda: 4.6554\n",
      "  Perda de treinamento: 4.2208, Perda de validação: 4.8019\n",
      "  Melhor modelo salvo (perda de validação: 4.8019)\n",
      "\n",
      "Época 12/50\n",
      "  Batch 20/358, Perda: 4.0594\n",
      "  Batch 40/358, Perda: 4.6068\n",
      "  Batch 60/358, Perda: 4.5579\n",
      "  Batch 80/358, Perda: 4.5437\n",
      "  Batch 100/358, Perda: 3.4011\n",
      "  Batch 120/358, Perda: 4.4375\n",
      "  Batch 140/358, Perda: 4.3944\n",
      "  Batch 160/358, Perda: 4.7625\n",
      "  Batch 180/358, Perda: 3.5960\n",
      "  Batch 200/358, Perda: 3.3998\n",
      "  Batch 220/358, Perda: 4.0063\n",
      "  Batch 240/358, Perda: 4.3718\n",
      "  Batch 260/358, Perda: 5.0778\n",
      "  Batch 280/358, Perda: 4.2902\n",
      "  Batch 300/358, Perda: 4.2181\n",
      "  Batch 320/358, Perda: 5.4488\n",
      "  Batch 340/358, Perda: 3.6815\n",
      "  Perda de treinamento: 4.2118, Perda de validação: 4.8018\n",
      "  Melhor modelo salvo (perda de validação: 4.8018)\n",
      "\n",
      "Época 13/50\n",
      "  Batch 20/358, Perda: 4.3539\n",
      "  Batch 40/358, Perda: 5.1243\n",
      "  Batch 60/358, Perda: 4.6077\n",
      "  Batch 80/358, Perda: 3.8340\n",
      "  Batch 100/358, Perda: 4.0041\n",
      "  Batch 120/358, Perda: 4.6162\n",
      "  Batch 140/358, Perda: 4.3606\n",
      "  Batch 160/358, Perda: 4.5363\n",
      "  Batch 180/358, Perda: 3.7460\n",
      "  Batch 200/358, Perda: 3.8095\n",
      "  Batch 220/358, Perda: 4.4967\n",
      "  Batch 240/358, Perda: 4.5388\n",
      "  Batch 260/358, Perda: 4.2924\n",
      "  Batch 280/358, Perda: 3.7855\n",
      "  Batch 300/358, Perda: 3.5957\n",
      "  Batch 320/358, Perda: 3.8224\n",
      "  Batch 340/358, Perda: 4.1199\n",
      "  Perda de treinamento: 4.2076, Perda de validação: 4.8017\n",
      "  Melhor modelo salvo (perda de validação: 4.8017)\n",
      "\n",
      "Época 14/50\n",
      "  Batch 20/358, Perda: 4.0245\n",
      "  Batch 40/358, Perda: 4.1142\n",
      "  Batch 60/358, Perda: 3.6847\n",
      "  Batch 80/358, Perda: 4.0130\n",
      "  Batch 100/358, Perda: 4.2898\n",
      "  Batch 120/358, Perda: 3.4907\n",
      "  Batch 140/358, Perda: 3.7827\n",
      "  Batch 160/358, Perda: 4.0739\n",
      "  Batch 180/358, Perda: 4.3509\n",
      "  Batch 200/358, Perda: 4.6007\n",
      "  Batch 220/358, Perda: 4.1839\n",
      "  Batch 240/358, Perda: 4.5380\n",
      "  Batch 260/358, Perda: 5.1299\n",
      "  Batch 280/358, Perda: 4.8954\n",
      "  Batch 300/358, Perda: 4.6757\n",
      "  Batch 320/358, Perda: 3.7458\n",
      "  Batch 340/358, Perda: 4.0876\n",
      "  Perda de treinamento: 4.2168, Perda de validação: 4.8017\n",
      "  Melhor modelo salvo (perda de validação: 4.8017)\n",
      "\n",
      "Época 15/50\n",
      "  Batch 20/358, Perda: 4.7573\n",
      "  Batch 40/358, Perda: 4.8095\n",
      "  Batch 60/358, Perda: 3.8621\n",
      "  Batch 80/358, Perda: 4.9138\n",
      "  Batch 100/358, Perda: 4.3219\n",
      "  Batch 120/358, Perda: 4.4585\n",
      "  Batch 140/358, Perda: 4.3793\n",
      "  Batch 160/358, Perda: 4.1381\n",
      "  Batch 180/358, Perda: 4.0040\n",
      "  Batch 200/358, Perda: 4.1796\n",
      "  Batch 220/358, Perda: 4.5150\n",
      "  Batch 240/358, Perda: 4.3570\n",
      "  Batch 260/358, Perda: 4.1515\n",
      "  Batch 280/358, Perda: 4.6403\n",
      "  Batch 300/358, Perda: 4.5629\n",
      "  Batch 320/358, Perda: 3.7649\n",
      "  Batch 340/358, Perda: 4.4211\n",
      "  Perda de treinamento: 4.2070, Perda de validação: 4.8018\n",
      "\n",
      "Época 16/50\n",
      "  Batch 20/358, Perda: 3.7317\n",
      "  Batch 40/358, Perda: 4.8463\n",
      "  Batch 60/358, Perda: 4.1512\n",
      "  Batch 80/358, Perda: 4.4705\n",
      "  Batch 100/358, Perda: 3.9105\n",
      "  Batch 120/358, Perda: 3.4425\n",
      "  Batch 140/358, Perda: 4.3512\n",
      "  Batch 160/358, Perda: 4.4203\n",
      "  Batch 180/358, Perda: 4.2716\n",
      "  Batch 200/358, Perda: 4.0993\n",
      "  Batch 220/358, Perda: 3.8697\n",
      "  Batch 240/358, Perda: 4.6017\n",
      "  Batch 260/358, Perda: 4.0872\n",
      "  Batch 280/358, Perda: 3.9424\n",
      "  Batch 300/358, Perda: 4.1782\n",
      "  Batch 320/358, Perda: 4.4818\n",
      "  Batch 340/358, Perda: 4.3950\n",
      "  Perda de treinamento: 4.1973, Perda de validação: 4.8018\n",
      "\n",
      "Época 17/50\n",
      "  Batch 20/358, Perda: 4.6050\n",
      "  Batch 40/358, Perda: 4.0484\n",
      "  Batch 60/358, Perda: 4.1262\n",
      "  Batch 80/358, Perda: 4.8997\n",
      "  Batch 100/358, Perda: 4.3423\n",
      "  Batch 120/358, Perda: 4.6765\n",
      "  Batch 140/358, Perda: 4.6977\n",
      "  Batch 160/358, Perda: 3.9626\n",
      "  Batch 180/358, Perda: 4.7865\n",
      "  Batch 200/358, Perda: 4.4216\n",
      "  Batch 220/358, Perda: 4.1454\n",
      "  Batch 240/358, Perda: 4.4251\n",
      "  Batch 260/358, Perda: 3.4634\n",
      "  Batch 280/358, Perda: 4.8141\n",
      "  Batch 300/358, Perda: 4.7520\n",
      "  Batch 320/358, Perda: 4.2350\n",
      "  Batch 340/358, Perda: 3.7282\n",
      "  Perda de treinamento: 4.2005, Perda de validação: 4.8018\n",
      "\n",
      "Época 18/50\n",
      "  Batch 20/358, Perda: 3.8499\n",
      "  Batch 40/358, Perda: 4.3305\n",
      "  Batch 60/358, Perda: 4.4604\n",
      "  Batch 80/358, Perda: 4.4689\n",
      "  Batch 100/358, Perda: 3.3640\n",
      "  Batch 120/358, Perda: 3.7123\n",
      "  Batch 140/358, Perda: 4.1039\n",
      "  Batch 160/358, Perda: 4.3218\n",
      "  Batch 180/358, Perda: 4.0910\n",
      "  Batch 200/358, Perda: 3.9265\n",
      "  Batch 220/358, Perda: 4.9859\n",
      "  Batch 240/358, Perda: 4.2418\n",
      "  Batch 260/358, Perda: 4.4935\n",
      "  Batch 280/358, Perda: 3.6796\n",
      "  Batch 300/358, Perda: 4.8160\n",
      "  Batch 320/358, Perda: 3.5194\n",
      "  Batch 340/358, Perda: 4.3676\n",
      "  Perda de treinamento: 4.2084, Perda de validação: 4.8018\n",
      "\n",
      "Época 19/50\n",
      "  Batch 20/358, Perda: 4.1932\n",
      "  Batch 40/358, Perda: 4.0725\n",
      "  Batch 60/358, Perda: 4.3204\n",
      "  Batch 80/358, Perda: 4.3227\n",
      "  Batch 100/358, Perda: 3.6724\n",
      "  Batch 120/358, Perda: 4.7154\n",
      "  Batch 140/358, Perda: 4.7398\n",
      "  Batch 160/358, Perda: 4.9051\n",
      "  Batch 180/358, Perda: 4.4999\n",
      "  Batch 200/358, Perda: 4.1444\n",
      "  Batch 220/358, Perda: 4.5767\n",
      "  Batch 240/358, Perda: 4.0956\n",
      "  Batch 260/358, Perda: 4.5938\n",
      "  Batch 280/358, Perda: 4.5575\n",
      "  Batch 300/358, Perda: 4.0250\n",
      "  Batch 320/358, Perda: 3.7660\n",
      "  Batch 340/358, Perda: 4.3484\n",
      "  Perda de treinamento: 4.2157, Perda de validação: 4.8018\n",
      "\n",
      "Época 20/50\n",
      "  Batch 20/358, Perda: 4.5851\n",
      "  Batch 40/358, Perda: 3.9834\n",
      "  Batch 60/358, Perda: 4.4908\n",
      "  Batch 80/358, Perda: 4.8272\n",
      "  Batch 100/358, Perda: 4.2302\n",
      "  Batch 120/358, Perda: 4.1347\n",
      "  Batch 140/358, Perda: 4.2430\n",
      "  Batch 160/358, Perda: 4.1148\n",
      "  Batch 180/358, Perda: 4.2936\n",
      "  Batch 200/358, Perda: 4.3637\n",
      "  Batch 220/358, Perda: 4.6232\n",
      "  Batch 240/358, Perda: 4.5932\n",
      "  Batch 260/358, Perda: 4.4906\n",
      "  Batch 280/358, Perda: 4.6269\n",
      "  Batch 300/358, Perda: 4.1466\n",
      "  Batch 320/358, Perda: 4.1428\n",
      "  Batch 340/358, Perda: 3.9944\n",
      "  Perda de treinamento: 4.2171, Perda de validação: 4.8018\n",
      "\n",
      "Época 21/50\n",
      "  Batch 20/358, Perda: 4.1638\n",
      "  Batch 40/358, Perda: 3.7043\n",
      "  Batch 60/358, Perda: 4.3529\n",
      "  Batch 80/358, Perda: 4.4065\n",
      "  Batch 100/358, Perda: 3.5578\n",
      "  Batch 120/358, Perda: 4.2376\n",
      "  Batch 140/358, Perda: 4.1478\n",
      "  Batch 160/358, Perda: 3.7687\n",
      "  Batch 180/358, Perda: 3.7773\n",
      "  Batch 200/358, Perda: 3.8845\n",
      "  Batch 220/358, Perda: 3.6091\n",
      "  Batch 240/358, Perda: 4.9509\n",
      "  Batch 260/358, Perda: 4.5260\n",
      "  Batch 280/358, Perda: 3.6882\n",
      "  Batch 300/358, Perda: 4.0695\n",
      "  Batch 320/358, Perda: 4.0350\n",
      "  Batch 340/358, Perda: 4.0067\n",
      "  Perda de treinamento: 4.2060, Perda de validação: 4.8018\n",
      "\n",
      "Época 22/50\n",
      "  Batch 20/358, Perda: 4.3089\n",
      "  Batch 40/358, Perda: 3.7430\n",
      "  Batch 60/358, Perda: 3.8374\n",
      "  Batch 80/358, Perda: 4.1303\n",
      "  Batch 100/358, Perda: 4.0541\n",
      "  Batch 120/358, Perda: 4.0472\n",
      "  Batch 140/358, Perda: 4.0886\n",
      "  Batch 160/358, Perda: 3.7869\n",
      "  Batch 180/358, Perda: 4.6956\n",
      "  Batch 200/358, Perda: 3.1688\n",
      "  Batch 220/358, Perda: 5.0525\n",
      "  Batch 240/358, Perda: 4.3271\n",
      "  Batch 260/358, Perda: 4.0343\n",
      "  Batch 280/358, Perda: 4.6837\n",
      "  Batch 300/358, Perda: 4.2523\n",
      "  Batch 320/358, Perda: 4.3475\n",
      "  Batch 340/358, Perda: 4.3270\n",
      "  Perda de treinamento: 4.2105, Perda de validação: 4.8018\n",
      "\n",
      "Época 23/50\n",
      "  Batch 20/358, Perda: 4.4506\n",
      "  Batch 40/358, Perda: 4.2585\n",
      "  Batch 60/358, Perda: 4.3434\n",
      "  Batch 80/358, Perda: 3.9306\n",
      "  Batch 100/358, Perda: 4.1421\n",
      "  Batch 120/358, Perda: 4.2042\n",
      "  Batch 140/358, Perda: 3.8015\n",
      "  Batch 160/358, Perda: 4.1212\n",
      "  Batch 180/358, Perda: 3.7642\n",
      "  Batch 200/358, Perda: 3.4592\n",
      "  Batch 220/358, Perda: 4.7183\n",
      "  Batch 240/358, Perda: 4.0046\n",
      "  Batch 260/358, Perda: 3.9796\n",
      "  Batch 280/358, Perda: 3.6928\n",
      "  Batch 300/358, Perda: 4.4997\n",
      "  Batch 320/358, Perda: 4.0990\n",
      "  Batch 340/358, Perda: 3.8317\n",
      "  Perda de treinamento: 4.2171, Perda de validação: 4.8018\n",
      "\n",
      "Época 24/50\n",
      "  Batch 20/358, Perda: 4.0952\n",
      "  Batch 40/358, Perda: 3.5850\n",
      "  Batch 60/358, Perda: 3.6448\n",
      "  Batch 80/358, Perda: 4.9086\n",
      "  Batch 100/358, Perda: 4.6508\n",
      "  Batch 120/358, Perda: 4.8048\n",
      "  Batch 140/358, Perda: 3.8172\n",
      "  Batch 160/358, Perda: 3.8906\n",
      "  Batch 180/358, Perda: 4.4545\n",
      "  Batch 200/358, Perda: 3.6966\n",
      "  Batch 220/358, Perda: 4.4619\n",
      "  Batch 240/358, Perda: 4.2501\n",
      "  Batch 260/358, Perda: 4.0848\n",
      "  Batch 280/358, Perda: 3.8814\n",
      "  Batch 300/358, Perda: 3.7867\n",
      "  Batch 320/358, Perda: 4.8371\n",
      "  Batch 340/358, Perda: 4.4483\n",
      "  Perda de treinamento: 4.2082, Perda de validação: 4.8018\n",
      "\n",
      "Época 25/50\n",
      "  Batch 20/358, Perda: 3.9346\n",
      "  Batch 40/358, Perda: 3.8989\n",
      "  Batch 60/358, Perda: 3.7987\n",
      "  Batch 80/358, Perda: 4.4241\n",
      "  Batch 100/358, Perda: 4.7097\n",
      "  Batch 120/358, Perda: 3.9276\n",
      "  Batch 140/358, Perda: 4.2644\n",
      "  Batch 160/358, Perda: 4.0922\n",
      "  Batch 180/358, Perda: 4.7858\n",
      "  Batch 200/358, Perda: 4.4289\n",
      "  Batch 220/358, Perda: 4.5988\n",
      "  Batch 240/358, Perda: 4.0724\n",
      "  Batch 260/358, Perda: 4.0187\n",
      "  Batch 280/358, Perda: 4.2838\n",
      "  Batch 300/358, Perda: 3.8032\n",
      "  Batch 320/358, Perda: 4.1410\n",
      "  Batch 340/358, Perda: 4.1771\n",
      "  Perda de treinamento: 4.2169, Perda de validação: 4.8018\n",
      "\n",
      "Época 26/50\n",
      "  Batch 20/358, Perda: 4.5026\n",
      "  Batch 40/358, Perda: 3.9345\n",
      "  Batch 60/358, Perda: 3.5499\n",
      "  Batch 80/358, Perda: 3.6867\n",
      "  Batch 100/358, Perda: 4.0243\n",
      "  Batch 120/358, Perda: 3.9996\n",
      "  Batch 140/358, Perda: 4.1046\n",
      "  Batch 160/358, Perda: 4.0591\n",
      "  Batch 180/358, Perda: 3.9874\n",
      "  Batch 200/358, Perda: 3.7147\n",
      "  Batch 220/358, Perda: 3.6747\n",
      "  Batch 240/358, Perda: 4.7335\n",
      "  Batch 260/358, Perda: 4.3655\n",
      "  Batch 280/358, Perda: 3.9780\n",
      "  Batch 300/358, Perda: 4.2537\n",
      "  Batch 320/358, Perda: 3.7566\n",
      "  Batch 340/358, Perda: 3.9109\n",
      "  Perda de treinamento: 4.2187, Perda de validação: 4.8018\n",
      "\n",
      "Época 27/50\n",
      "  Batch 20/358, Perda: 3.6870\n",
      "  Batch 40/358, Perda: 4.0283\n",
      "  Batch 60/358, Perda: 4.5885\n",
      "  Batch 80/358, Perda: 3.9700\n",
      "  Batch 100/358, Perda: 3.7931\n",
      "  Batch 120/358, Perda: 3.8389\n",
      "  Batch 140/358, Perda: 3.6656\n",
      "  Batch 160/358, Perda: 4.9564\n",
      "  Batch 180/358, Perda: 4.2926\n",
      "  Batch 200/358, Perda: 3.9705\n",
      "  Batch 220/358, Perda: 4.0302\n",
      "  Batch 240/358, Perda: 4.4073\n",
      "  Batch 260/358, Perda: 3.6830\n",
      "  Batch 280/358, Perda: 4.1990\n",
      "  Batch 300/358, Perda: 4.1387\n",
      "  Batch 320/358, Perda: 3.9345\n",
      "  Batch 340/358, Perda: 4.4261\n",
      "  Perda de treinamento: 4.2015, Perda de validação: 4.8017\n",
      "  Melhor modelo salvo (perda de validação: 4.8017)\n",
      "\n",
      "Época 28/50\n",
      "  Batch 20/358, Perda: 4.8476\n",
      "  Batch 40/358, Perda: 3.2415\n",
      "  Batch 60/358, Perda: 4.4202\n",
      "  Batch 80/358, Perda: 4.1013\n",
      "  Batch 100/358, Perda: 4.1388\n",
      "  Batch 120/358, Perda: 4.0334\n",
      "  Batch 140/358, Perda: 4.5261\n",
      "  Batch 160/358, Perda: 4.0054\n",
      "  Batch 180/358, Perda: 4.1836\n",
      "  Batch 200/358, Perda: 3.5885\n",
      "  Batch 220/358, Perda: 3.9531\n",
      "  Batch 240/358, Perda: 4.7178\n",
      "  Batch 260/358, Perda: 4.1401\n",
      "  Batch 280/358, Perda: 4.1792\n",
      "  Batch 300/358, Perda: 3.7394\n",
      "  Batch 320/358, Perda: 3.9865\n",
      "  Batch 340/358, Perda: 4.7262\n",
      "  Perda de treinamento: 4.2131, Perda de validação: 4.8018\n",
      "\n",
      "Época 29/50\n",
      "  Batch 20/358, Perda: 4.2582\n",
      "  Batch 40/358, Perda: 4.2880\n",
      "  Batch 60/358, Perda: 4.3082\n",
      "  Batch 80/358, Perda: 3.7936\n",
      "  Batch 100/358, Perda: 3.4320\n",
      "  Batch 120/358, Perda: 4.1192\n",
      "  Batch 140/358, Perda: 4.3978\n",
      "  Batch 160/358, Perda: 4.3889\n",
      "  Batch 180/358, Perda: 4.5268\n",
      "  Batch 200/358, Perda: 3.6863\n",
      "  Batch 220/358, Perda: 3.6416\n",
      "  Batch 240/358, Perda: 4.4569\n",
      "  Batch 260/358, Perda: 4.9413\n",
      "  Batch 280/358, Perda: 4.0752\n",
      "  Batch 300/358, Perda: 4.3254\n",
      "  Batch 320/358, Perda: 4.2413\n",
      "  Batch 340/358, Perda: 4.4942\n",
      "  Perda de treinamento: 4.2137, Perda de validação: 4.8018\n",
      "\n",
      "Época 30/50\n",
      "  Batch 20/358, Perda: 5.1111\n",
      "  Batch 40/358, Perda: 4.0684\n",
      "  Batch 60/358, Perda: 4.2553\n",
      "  Batch 80/358, Perda: 3.8501\n",
      "  Batch 100/358, Perda: 3.8298\n",
      "  Batch 120/358, Perda: 3.8423\n",
      "  Batch 140/358, Perda: 3.5438\n",
      "  Batch 160/358, Perda: 3.9037\n",
      "  Batch 180/358, Perda: 4.2184\n",
      "  Batch 200/358, Perda: 3.4576\n",
      "  Batch 220/358, Perda: 4.7645\n",
      "  Batch 240/358, Perda: 3.7418\n",
      "  Batch 260/358, Perda: 4.4424\n",
      "  Batch 280/358, Perda: 4.9888\n",
      "  Batch 300/358, Perda: 4.4571\n",
      "  Batch 320/358, Perda: 3.6049\n",
      "  Batch 340/358, Perda: 3.8775\n",
      "  Perda de treinamento: 4.2043, Perda de validação: 4.8018\n",
      "\n",
      "Época 31/50\n",
      "  Batch 20/358, Perda: 4.0642\n",
      "  Batch 40/358, Perda: 4.0335\n",
      "  Batch 60/358, Perda: 4.5257\n",
      "  Batch 80/358, Perda: 4.2913\n",
      "  Batch 100/358, Perda: 3.7546\n",
      "  Batch 120/358, Perda: 3.4041\n",
      "  Batch 140/358, Perda: 4.0302\n",
      "  Batch 160/358, Perda: 4.4228\n",
      "  Batch 180/358, Perda: 4.7924\n",
      "  Batch 200/358, Perda: 4.4964\n",
      "  Batch 220/358, Perda: 4.3324\n",
      "  Batch 240/358, Perda: 4.2252\n",
      "  Batch 260/358, Perda: 3.9759\n",
      "  Batch 280/358, Perda: 3.8388\n",
      "  Batch 300/358, Perda: 4.0993\n",
      "  Batch 320/358, Perda: 4.2686\n",
      "  Batch 340/358, Perda: 3.9871\n",
      "  Perda de treinamento: 4.2148, Perda de validação: 4.8018\n",
      "\n",
      "Época 32/50\n",
      "  Batch 20/358, Perda: 4.6994\n",
      "  Batch 40/358, Perda: 3.6419\n",
      "  Batch 60/358, Perda: 4.7329\n",
      "  Batch 80/358, Perda: 4.2938\n",
      "  Batch 100/358, Perda: 4.2439\n",
      "  Batch 120/358, Perda: 4.0593\n",
      "  Batch 140/358, Perda: 3.6686\n",
      "  Batch 160/358, Perda: 4.4171\n",
      "  Batch 180/358, Perda: 4.3001\n",
      "  Batch 200/358, Perda: 4.5793\n",
      "  Batch 220/358, Perda: 3.5363\n",
      "  Batch 240/358, Perda: 4.8403\n",
      "  Batch 260/358, Perda: 4.1287\n",
      "  Batch 280/358, Perda: 4.7986\n",
      "  Batch 300/358, Perda: 4.2134\n",
      "  Batch 320/358, Perda: 3.8663\n",
      "  Batch 340/358, Perda: 4.4176\n",
      "  Perda de treinamento: 4.2130, Perda de validação: 4.8018\n",
      "\n",
      "Época 33/50\n",
      "  Batch 20/358, Perda: 4.4028\n",
      "  Batch 40/358, Perda: 4.3316\n",
      "  Batch 60/358, Perda: 4.2488\n",
      "  Batch 80/358, Perda: 4.8246\n",
      "  Batch 100/358, Perda: 4.0012\n",
      "  Batch 120/358, Perda: 3.8636\n",
      "  Batch 140/358, Perda: 4.0443\n",
      "  Batch 160/358, Perda: 3.8427\n",
      "  Batch 180/358, Perda: 3.7749\n",
      "  Batch 200/358, Perda: 3.0906\n",
      "  Batch 220/358, Perda: 3.9979\n",
      "  Batch 240/358, Perda: 4.5842\n",
      "  Batch 260/358, Perda: 3.9095\n",
      "  Batch 280/358, Perda: 4.1915\n",
      "  Batch 300/358, Perda: 5.0275\n",
      "  Batch 320/358, Perda: 4.0510\n",
      "  Batch 340/358, Perda: 3.7432\n",
      "  Perda de treinamento: 4.2094, Perda de validação: 4.8018\n",
      "\n",
      "Época 34/50\n",
      "  Batch 20/358, Perda: 4.4390\n",
      "  Batch 40/358, Perda: 3.7153\n",
      "  Batch 60/358, Perda: 4.1134\n",
      "  Batch 80/358, Perda: 4.5909\n",
      "  Batch 100/358, Perda: 3.7682\n",
      "  Batch 120/358, Perda: 4.2255\n",
      "  Batch 140/358, Perda: 3.4738\n",
      "  Batch 160/358, Perda: 4.1632\n",
      "  Batch 180/358, Perda: 3.8963\n",
      "  Batch 200/358, Perda: 4.2130\n",
      "  Batch 220/358, Perda: 4.2362\n",
      "  Batch 240/358, Perda: 3.5863\n",
      "  Batch 260/358, Perda: 4.6020\n",
      "  Batch 280/358, Perda: 4.3247\n",
      "  Batch 300/358, Perda: 4.7506\n",
      "  Batch 320/358, Perda: 3.7944\n",
      "  Batch 340/358, Perda: 4.3465\n",
      "  Perda de treinamento: 4.2184, Perda de validação: 4.8018\n",
      "\n",
      "Época 35/50\n",
      "  Batch 20/358, Perda: 5.1105\n",
      "  Batch 40/358, Perda: 4.1765\n",
      "  Batch 60/358, Perda: 4.7422\n",
      "  Batch 80/358, Perda: 4.0773\n",
      "  Batch 100/358, Perda: 4.4900\n",
      "  Batch 120/358, Perda: 3.5415\n",
      "  Batch 140/358, Perda: 4.1439\n",
      "  Batch 160/358, Perda: 4.2911\n",
      "  Batch 180/358, Perda: 4.1983\n",
      "  Batch 200/358, Perda: 4.2349\n",
      "  Batch 220/358, Perda: 4.2249\n",
      "  Batch 240/358, Perda: 3.3945\n",
      "  Batch 260/358, Perda: 3.5108\n",
      "  Batch 280/358, Perda: 4.1167\n",
      "  Batch 300/358, Perda: 4.2131\n",
      "  Batch 320/358, Perda: 4.5437\n",
      "  Batch 340/358, Perda: 4.7466\n",
      "  Perda de treinamento: 4.1971, Perda de validação: 4.8018\n",
      "\n",
      "Época 36/50\n",
      "  Batch 20/358, Perda: 4.2471\n",
      "  Batch 40/358, Perda: 4.2484\n",
      "  Batch 60/358, Perda: 4.6234\n",
      "  Batch 80/358, Perda: 4.4549\n",
      "  Batch 100/358, Perda: 4.6964\n",
      "  Batch 120/358, Perda: 4.1849\n",
      "  Batch 140/358, Perda: 3.7931\n",
      "  Batch 160/358, Perda: 4.8867\n",
      "  Batch 180/358, Perda: 4.8273\n",
      "  Batch 200/358, Perda: 4.3307\n",
      "  Batch 220/358, Perda: 4.8616\n",
      "  Batch 240/358, Perda: 4.0262\n",
      "  Batch 260/358, Perda: 4.1933\n",
      "  Batch 280/358, Perda: 4.1679\n",
      "  Batch 300/358, Perda: 4.2872\n",
      "  Batch 320/358, Perda: 4.4337\n",
      "  Batch 340/358, Perda: 3.7107\n",
      "  Perda de treinamento: 4.2070, Perda de validação: 4.8018\n",
      "\n",
      "Época 37/50\n",
      "  Batch 20/358, Perda: 4.3155\n",
      "  Batch 40/358, Perda: 3.9357\n",
      "  Batch 60/358, Perda: 3.8722\n",
      "  Batch 80/358, Perda: 4.4304\n",
      "  Batch 100/358, Perda: 4.3271\n",
      "  Batch 120/358, Perda: 3.8683\n",
      "  Batch 140/358, Perda: 4.7911\n",
      "  Batch 160/358, Perda: 4.3744\n",
      "  Batch 180/358, Perda: 3.9249\n",
      "  Batch 200/358, Perda: 4.2250\n",
      "  Batch 220/358, Perda: 4.3134\n",
      "  Batch 240/358, Perda: 4.5121\n",
      "  Batch 260/358, Perda: 4.6275\n",
      "  Batch 280/358, Perda: 4.1536\n",
      "  Batch 300/358, Perda: 3.8224\n",
      "  Batch 320/358, Perda: 4.2177\n",
      "  Batch 340/358, Perda: 4.6848\n",
      "  Perda de treinamento: 4.2137, Perda de validação: 4.8017\n",
      "\n",
      "Época 38/50\n",
      "  Batch 20/358, Perda: 4.4646\n",
      "  Batch 40/358, Perda: 4.4249\n",
      "  Batch 60/358, Perda: 3.9406\n",
      "  Batch 80/358, Perda: 3.2318\n",
      "  Batch 100/358, Perda: 4.0560\n",
      "  Batch 120/358, Perda: 4.0435\n",
      "  Batch 140/358, Perda: 4.5722\n",
      "  Batch 160/358, Perda: 4.0926\n",
      "  Batch 180/358, Perda: 4.3503\n",
      "  Batch 200/358, Perda: 3.8554\n",
      "  Batch 220/358, Perda: 5.0234\n",
      "  Batch 240/358, Perda: 4.1830\n",
      "  Batch 260/358, Perda: 4.4425\n",
      "  Batch 280/358, Perda: 3.8383\n",
      "  Batch 300/358, Perda: 4.2697\n",
      "  Batch 320/358, Perda: 4.6061\n",
      "  Batch 340/358, Perda: 3.6474\n",
      "  Perda de treinamento: 4.2269, Perda de validação: 4.8018\n",
      "\n",
      "Época 39/50\n",
      "  Batch 20/358, Perda: 4.5619\n",
      "  Batch 40/358, Perda: 3.7184\n",
      "  Batch 60/358, Perda: 4.5838\n",
      "  Batch 80/358, Perda: 3.8084\n",
      "  Batch 100/358, Perda: 4.0740\n",
      "  Batch 120/358, Perda: 3.6466\n",
      "  Batch 140/358, Perda: 4.3294\n",
      "  Batch 160/358, Perda: 4.1594\n",
      "  Batch 180/358, Perda: 4.1359\n",
      "  Batch 200/358, Perda: 3.9466\n",
      "  Batch 220/358, Perda: 4.4517\n",
      "  Batch 240/358, Perda: 4.0331\n",
      "  Batch 260/358, Perda: 3.9644\n",
      "  Batch 280/358, Perda: 3.8903\n",
      "  Batch 300/358, Perda: 4.3677\n",
      "  Batch 320/358, Perda: 3.8313\n",
      "  Batch 340/358, Perda: 4.0802\n",
      "  Perda de treinamento: 4.2149, Perda de validação: 4.8018\n",
      "\n",
      "Época 40/50\n",
      "  Batch 20/358, Perda: 4.0812\n",
      "  Batch 40/358, Perda: 4.5943\n",
      "  Batch 60/358, Perda: 4.4785\n",
      "  Batch 80/358, Perda: 3.7607\n",
      "  Batch 100/358, Perda: 4.1596\n",
      "  Batch 120/358, Perda: 4.0325\n",
      "  Batch 140/358, Perda: 4.7080\n",
      "  Batch 160/358, Perda: 4.1165\n",
      "  Batch 180/358, Perda: 4.1770\n",
      "  Batch 200/358, Perda: 4.0323\n",
      "  Batch 220/358, Perda: 4.1418\n",
      "  Batch 240/358, Perda: 4.0911\n",
      "  Batch 260/358, Perda: 4.3826\n",
      "  Batch 280/358, Perda: 4.1852\n",
      "  Batch 300/358, Perda: 3.2522\n",
      "  Batch 320/358, Perda: 3.6177\n",
      "  Batch 340/358, Perda: 4.2343\n",
      "  Perda de treinamento: 4.2139, Perda de validação: 4.8017\n",
      "\n",
      "Época 41/50\n",
      "  Batch 20/358, Perda: 3.8042\n",
      "  Batch 40/358, Perda: 4.0696\n",
      "  Batch 60/358, Perda: 4.1006\n",
      "  Batch 80/358, Perda: 4.3358\n",
      "  Batch 100/358, Perda: 4.1130\n",
      "  Batch 120/358, Perda: 3.6750\n",
      "  Batch 140/358, Perda: 4.7123\n",
      "  Batch 160/358, Perda: 3.5213\n",
      "  Batch 180/358, Perda: 4.4454\n",
      "  Batch 200/358, Perda: 3.9863\n",
      "  Batch 220/358, Perda: 4.5115\n",
      "  Batch 240/358, Perda: 4.4374\n",
      "  Batch 260/358, Perda: 4.2615\n",
      "  Batch 280/358, Perda: 4.8872\n",
      "  Batch 300/358, Perda: 3.8334\n",
      "  Batch 320/358, Perda: 3.9076\n",
      "  Batch 340/358, Perda: 4.8285\n",
      "  Perda de treinamento: 4.2096, Perda de validação: 4.8018\n",
      "\n",
      "Época 42/50\n",
      "  Batch 20/358, Perda: 4.2603\n",
      "  Batch 40/358, Perda: 4.1341\n",
      "  Batch 60/358, Perda: 4.2428\n",
      "  Batch 80/358, Perda: 3.5837\n",
      "  Batch 100/358, Perda: 4.1314\n",
      "  Batch 120/358, Perda: 4.6329\n",
      "  Batch 140/358, Perda: 3.6775\n",
      "  Batch 160/358, Perda: 3.9830\n",
      "  Batch 180/358, Perda: 4.6321\n",
      "  Batch 200/358, Perda: 4.3981\n",
      "  Batch 220/358, Perda: 4.5574\n",
      "  Batch 240/358, Perda: 4.4970\n",
      "  Batch 260/358, Perda: 4.1353\n",
      "  Batch 280/358, Perda: 4.4388\n",
      "  Batch 300/358, Perda: 4.1032\n",
      "  Batch 320/358, Perda: 4.1369\n",
      "  Batch 340/358, Perda: 4.1384\n",
      "  Perda de treinamento: 4.2139, Perda de validação: 4.8018\n",
      "\n",
      "Época 43/50\n",
      "  Batch 20/358, Perda: 4.0420\n",
      "  Batch 40/358, Perda: 4.2044\n",
      "  Batch 60/358, Perda: 3.6589\n",
      "  Batch 80/358, Perda: 4.4211\n",
      "  Batch 100/358, Perda: 3.9587\n",
      "  Batch 120/358, Perda: 4.5955\n",
      "  Batch 140/358, Perda: 4.6655\n",
      "  Batch 160/358, Perda: 4.3762\n",
      "  Batch 180/358, Perda: 3.7354\n",
      "  Batch 200/358, Perda: 4.7002\n",
      "  Batch 220/358, Perda: 4.0513\n",
      "  Batch 240/358, Perda: 3.5925\n",
      "  Batch 260/358, Perda: 3.3901\n",
      "  Batch 280/358, Perda: 4.1212\n",
      "  Batch 300/358, Perda: 4.8569\n",
      "  Batch 320/358, Perda: 4.4578\n",
      "  Batch 340/358, Perda: 4.1141\n",
      "  Perda de treinamento: 4.2094, Perda de validação: 4.8017\n",
      "\n",
      "Época 44/50\n",
      "  Batch 20/358, Perda: 4.4310\n",
      "  Batch 40/358, Perda: 4.6319\n",
      "  Batch 60/358, Perda: 4.0904\n",
      "  Batch 80/358, Perda: 3.8330\n",
      "  Batch 100/358, Perda: 4.5712\n",
      "  Batch 120/358, Perda: 3.8771\n",
      "  Batch 140/358, Perda: 3.8289\n",
      "  Batch 160/358, Perda: 4.0024\n",
      "  Batch 180/358, Perda: 4.5204\n",
      "  Batch 200/358, Perda: 4.4469\n",
      "  Batch 220/358, Perda: 3.5668\n",
      "  Batch 240/358, Perda: 4.8570\n",
      "  Batch 260/358, Perda: 4.1545\n",
      "  Batch 280/358, Perda: 3.7141\n",
      "  Batch 300/358, Perda: 4.6630\n",
      "  Batch 320/358, Perda: 4.6404\n",
      "  Batch 340/358, Perda: 4.2628\n",
      "  Perda de treinamento: 4.2204, Perda de validação: 4.8018\n",
      "\n",
      "Época 45/50\n",
      "  Batch 20/358, Perda: 4.3600\n",
      "  Batch 40/358, Perda: 3.6176\n",
      "  Batch 60/358, Perda: 5.3610\n",
      "  Batch 80/358, Perda: 4.3750\n",
      "  Batch 100/358, Perda: 3.8122\n",
      "  Batch 120/358, Perda: 4.6827\n",
      "  Batch 140/358, Perda: 4.5243\n",
      "  Batch 160/358, Perda: 4.0336\n",
      "  Batch 180/358, Perda: 3.5890\n",
      "  Batch 200/358, Perda: 4.1553\n",
      "  Batch 220/358, Perda: 4.3833\n",
      "  Batch 240/358, Perda: 3.7976\n",
      "  Batch 260/358, Perda: 3.8717\n",
      "  Batch 280/358, Perda: 5.0287\n",
      "  Batch 300/358, Perda: 4.4618\n",
      "  Batch 320/358, Perda: 4.1895\n",
      "  Batch 340/358, Perda: 4.2328\n",
      "  Perda de treinamento: 4.2174, Perda de validação: 4.8018\n",
      "\n",
      "Época 46/50\n",
      "  Batch 20/358, Perda: 4.8046\n",
      "  Batch 40/358, Perda: 4.8888\n",
      "  Batch 60/358, Perda: 4.1316\n",
      "  Batch 80/358, Perda: 4.1606\n",
      "  Batch 100/358, Perda: 3.7981\n",
      "  Batch 120/358, Perda: 4.3611\n",
      "  Batch 140/358, Perda: 3.5818\n",
      "  Batch 160/358, Perda: 4.6175\n",
      "  Batch 180/358, Perda: 4.9947\n",
      "  Batch 200/358, Perda: 4.2041\n",
      "  Batch 220/358, Perda: 5.5446\n",
      "  Batch 240/358, Perda: 3.2513\n",
      "  Batch 260/358, Perda: 3.8454\n",
      "  Batch 280/358, Perda: 4.1204\n",
      "  Batch 300/358, Perda: 3.8329\n",
      "  Batch 320/358, Perda: 4.4704\n",
      "  Batch 340/358, Perda: 3.7854\n",
      "  Perda de treinamento: 4.2129, Perda de validação: 4.8018\n",
      "\n",
      "Época 47/50\n",
      "  Batch 20/358, Perda: 4.5782\n",
      "  Batch 40/358, Perda: 4.2720\n",
      "  Batch 60/358, Perda: 4.4392\n",
      "  Batch 80/358, Perda: 4.6824\n",
      "  Batch 100/358, Perda: 4.1245\n",
      "  Batch 120/358, Perda: 4.3360\n",
      "  Batch 140/358, Perda: 4.0926\n",
      "  Batch 160/358, Perda: 4.9236\n",
      "  Batch 180/358, Perda: 4.5609\n",
      "  Batch 200/358, Perda: 4.1288\n",
      "  Batch 220/358, Perda: 3.6546\n",
      "  Batch 240/358, Perda: 3.9163\n",
      "  Batch 260/358, Perda: 3.6592\n",
      "  Batch 280/358, Perda: 3.4855\n",
      "  Batch 300/358, Perda: 3.8687\n",
      "  Batch 320/358, Perda: 4.5204\n",
      "  Batch 340/358, Perda: 4.0738\n",
      "  Perda de treinamento: 4.2171, Perda de validação: 4.8018\n",
      "\n",
      "Época 48/50\n",
      "  Batch 20/358, Perda: 4.1894\n",
      "  Batch 40/358, Perda: 4.5470\n",
      "  Batch 60/358, Perda: 3.5565\n",
      "  Batch 80/358, Perda: 4.3625\n",
      "  Batch 100/358, Perda: 3.9341\n",
      "  Batch 120/358, Perda: 4.8775\n",
      "  Batch 140/358, Perda: 4.4391\n",
      "  Batch 160/358, Perda: 4.7201\n",
      "  Batch 180/358, Perda: 4.2685\n",
      "  Batch 200/358, Perda: 4.9647\n",
      "  Batch 220/358, Perda: 4.0765\n",
      "  Batch 240/358, Perda: 4.0563\n",
      "  Batch 260/358, Perda: 3.5116\n",
      "  Batch 280/358, Perda: 4.3453\n",
      "  Batch 300/358, Perda: 4.4996\n",
      "  Batch 320/358, Perda: 4.5646\n",
      "  Batch 340/358, Perda: 4.3517\n",
      "  Perda de treinamento: 4.2138, Perda de validação: 4.8018\n",
      "\n",
      "Época 49/50\n",
      "  Batch 20/358, Perda: 4.2031\n",
      "  Batch 40/358, Perda: 4.1594\n",
      "  Batch 60/358, Perda: 4.5281\n",
      "  Batch 80/358, Perda: 4.5773\n",
      "  Batch 100/358, Perda: 4.3349\n",
      "  Batch 120/358, Perda: 4.5830\n",
      "  Batch 140/358, Perda: 4.3803\n",
      "  Batch 160/358, Perda: 4.3969\n",
      "  Batch 180/358, Perda: 4.5726\n",
      "  Batch 200/358, Perda: 4.3879\n",
      "  Batch 220/358, Perda: 3.9895\n",
      "  Batch 240/358, Perda: 3.8922\n",
      "  Batch 260/358, Perda: 4.7627\n",
      "  Batch 280/358, Perda: 3.5017\n",
      "  Batch 300/358, Perda: 4.9722\n",
      "  Batch 320/358, Perda: 5.0514\n",
      "  Batch 340/358, Perda: 3.7551\n",
      "  Perda de treinamento: 4.2112, Perda de validação: 4.8018\n",
      "\n",
      "Época 50/50\n",
      "  Batch 20/358, Perda: 4.2424\n",
      "  Batch 40/358, Perda: 4.0515\n",
      "  Batch 60/358, Perda: 4.4608\n",
      "  Batch 80/358, Perda: 4.4854\n",
      "  Batch 100/358, Perda: 4.7973\n",
      "  Batch 120/358, Perda: 4.2139\n",
      "  Batch 140/358, Perda: 4.4661\n",
      "  Batch 160/358, Perda: 4.1346\n",
      "  Batch 180/358, Perda: 3.4791\n",
      "  Batch 200/358, Perda: 4.4760\n",
      "  Batch 220/358, Perda: 5.0711\n",
      "  Batch 240/358, Perda: 3.9879\n",
      "  Batch 260/358, Perda: 4.5613\n",
      "  Batch 280/358, Perda: 3.9606\n",
      "  Batch 300/358, Perda: 3.8640\n",
      "  Batch 320/358, Perda: 4.2184\n",
      "  Batch 340/358, Perda: 4.7565\n",
      "  Perda de treinamento: 4.2219, Perda de validação: 4.8018\n",
      "\n",
      "Treinamento completo em 272.86 minutos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edvar\\AppData\\Local\\Temp\\ipykernel_11132\\1815129545.py:529: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('best_ssdlite_mobilenet.pth', map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor modelo carregado com sucesso (época 26).\n",
      "Exportando modelo para ONNX...\n",
      "Erro ao exportar para ONNX: images is expected to be a list of 3d tensors of shape [C, H, W], got torch.Size([1, 3, 640, 640])\n",
      "Tentando exportação alternativa...\n",
      "Erro na exportação alternativa: images is expected to be a list of 3d tensors of shape [C, H, W], got torch.Size([1, 3, 640, 640])\n",
      "Tentando exportar apenas o backbone...\n",
      "Backbone exportado com sucesso para mobilenet_backbone.onnx\n",
      "Salvando informações do modelo...\n",
      "Informações do modelo salvas em model_info.txt\n",
      "Processo concluído!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision.models.detection import ssdlite320_mobilenet_v3_large, SSDLite320_MobileNet_V3_Large_Weights\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import VOCDetection\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "print(f\"Versão PyTorch: {torch.__version__}\")\n",
    "print(f\"Versão TorchVision: {torchvision.__version__}\")\n",
    "\n",
    "def get_voc_dataset(root='./data'):\n",
    "    \"\"\"Usa o dataset Pascal VOC 2012 que já foi baixado.\"\"\"\n",
    "    # Transformações para aumentação de dados\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((640, 640)),\n",
    "        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((640, 640)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Dataset de treino (usando VOC2012 train)\n",
    "    train_dataset = VOCDetection(\n",
    "        root=root,\n",
    "        year='2012',\n",
    "        image_set='train',\n",
    "        download=True,  # Não baixar novamente\n",
    "        transform=train_transform,\n",
    "    )\n",
    "\n",
    "    # Dataset de validação (usando parte do VOC2012)\n",
    "    val_dataset = VOCDetection(\n",
    "        root=root,\n",
    "        year='2012',\n",
    "        image_set='val',\n",
    "        download=True,  # Não baixar novamente\n",
    "        transform=val_transform,\n",
    "    )\n",
    "\n",
    "    print(f\"Tamanho do dataset de treino: {len(train_dataset)}\")\n",
    "    print(f\"Tamanho do dataset de validação: {len(val_dataset)}\")\n",
    "\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Função de colagem personalizada para processar amostras de lotes.\"\"\"\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "def create_model(num_classes=21):  # 20 classes + background\n",
    "    \"\"\"Cria um modelo SSDLite320 com backbone MobileNetV3 para detecção de objetos.\"\"\"\n",
    "    # Criar modelo com pesos pré-treinados\n",
    "    weights = SSDLite320_MobileNet_V3_Large_Weights.DEFAULT\n",
    "    model = ssdlite320_mobilenet_v3_large(weights=weights)\n",
    "\n",
    "    # Modificar o número de classes, se necessário\n",
    "    if num_classes != 91:  # 91 é o padrão para COCO\n",
    "        # Inspecionar o modelo para entender a estrutura\n",
    "        print(\"Adaptando modelo para classes VOC...\")\n",
    "\n",
    "        # Obter e substituir as camadas de classificação\n",
    "        try:\n",
    "            # Para TorchVision 0.20.1, acessar diretamente a camada cls_logits\n",
    "            cls_logits = model.head.classification_head.cls_logits\n",
    "\n",
    "            # Obter dimensões da camada existente\n",
    "            in_channels = cls_logits.in_channels\n",
    "            kernel_size = cls_logits.kernel_size\n",
    "            stride = cls_logits.stride\n",
    "            padding = cls_logits.padding\n",
    "\n",
    "            # Obter número de âncoras do tamanho de saída atual\n",
    "            out_channels = cls_logits.out_channels\n",
    "            num_anchors = out_channels // 91  # 91 classes padrão COCO\n",
    "\n",
    "            # Criar nova camada de classificação\n",
    "            new_cls_logits = nn.Conv2d(\n",
    "                in_channels,\n",
    "                num_anchors * num_classes,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding\n",
    "            )\n",
    "\n",
    "            # Inicializar pesos\n",
    "            nn.init.normal_(new_cls_logits.weight, std=0.01)\n",
    "            nn.init.constant_(new_cls_logits.bias, 0)\n",
    "\n",
    "            # Substituir camada\n",
    "            model.head.classification_head.cls_logits = new_cls_logits\n",
    "            print(f\"Camada de classificação adaptada para {num_classes} classes\")\n",
    "            print(f\"Estrutura cls_logits: in_channels={in_channels}, num_anchors={num_anchors}\")\n",
    "        except AttributeError:\n",
    "            # Abordagem alternativa\n",
    "            print(\"Erro ao acessar 'in_channels'. Tentando abordagem alternativa...\")\n",
    "\n",
    "            # Explorar estrutura do modelo\n",
    "            print(\"Explorando estrutura do modelo:\")\n",
    "            print(\"Head:\", model.head.__class__.__name__)\n",
    "            print(\"Classification head:\", model.head.classification_head.__class__.__name__)\n",
    "\n",
    "            # Exibir todos os atributos da classification_head\n",
    "            cls_head_attrs = dir(model.head.classification_head)\n",
    "            print(\"Atributos da cabeça de classificação:\", [a for a in cls_head_attrs if not a.startswith('_')])\n",
    "\n",
    "            # Tentar acessar cls_logits\n",
    "            if hasattr(model.head.classification_head, 'cls_logits'):\n",
    "                cls_logits = model.head.classification_head.cls_logits\n",
    "                print(f\"cls_logits encontrado: {cls_logits}\")\n",
    "                print(f\"cls_logits tipo: {type(cls_logits)}\")\n",
    "\n",
    "                # Tentar modificar usando a arquitetura existente\n",
    "                try:\n",
    "                    # Obter número de âncoras analisando o tensor de saída\n",
    "                    num_classes_original = 91  # COCO classes\n",
    "                    out_channels = cls_logits.out_channels\n",
    "                    num_anchors = out_channels // num_classes_original\n",
    "\n",
    "                    # Criar nova camada com parâmetros existentes\n",
    "                    new_cls_logits = nn.Conv2d(\n",
    "                        cls_logits.in_channels,\n",
    "                        num_anchors * num_classes,\n",
    "                        kernel_size=cls_logits.kernel_size,\n",
    "                        padding=cls_logits.padding\n",
    "                    )\n",
    "\n",
    "                    # Inicializar pesos\n",
    "                    nn.init.normal_(new_cls_logits.weight, std=0.01)\n",
    "                    nn.init.constant_(new_cls_logits.bias, 0)\n",
    "\n",
    "                    # Substituir camada\n",
    "                    model.head.classification_head.cls_logits = new_cls_logits\n",
    "                    print(f\"Camada de classificação adaptada para {num_classes} classes\")\n",
    "                except Exception as e2:\n",
    "                    print(f\"Erro na segunda tentativa: {e2}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def voc_to_coco_format(target, device):\n",
    "    \"\"\"Converte o formato de anotação Pascal VOC para o formato esperado pelo modelo.\"\"\"\n",
    "    boxes = []\n",
    "    labels = []\n",
    "\n",
    "    # Mapeamento de classes Pascal VOC para índices\n",
    "    voc_classes = [\n",
    "        'background',  # Classe 0 é o background\n",
    "        'aeroplane', 'bicycle', 'bird', 'boat', 'bottle',\n",
    "        'bus', 'car', 'cat', 'chair', 'cow',\n",
    "        'diningtable', 'dog', 'horse', 'motorbike', 'person',\n",
    "        'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'\n",
    "    ]\n",
    "    class_to_idx = {cls: i for i, cls in enumerate(voc_classes)}\n",
    "\n",
    "    try:\n",
    "        for obj in target['annotation']['object']:\n",
    "            bbox = obj['bndbox']\n",
    "            xmin = float(bbox['xmin'])\n",
    "            ymin = float(bbox['ymin'])\n",
    "            xmax = float(bbox['xmax'])\n",
    "            ymax = float(bbox['ymax'])\n",
    "\n",
    "            # Verificar se as coordenadas são válidas\n",
    "            if xmax > xmin and ymax > ymin:\n",
    "                boxes.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "                # Obter classe (com fallback para 'person' se não encontrada)\n",
    "                class_name = obj['name']\n",
    "                class_idx = class_to_idx.get(class_name, class_to_idx['person'])\n",
    "                labels.append(class_idx)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar target: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Retornar None se não houver caixas válidas\n",
    "    if not boxes:\n",
    "        return None\n",
    "\n",
    "    # Criar dicionário no formato esperado\n",
    "    target_dict = {\n",
    "        'boxes': torch.tensor(boxes, dtype=torch.float32, device=device),\n",
    "        'labels': torch.tensor(labels, dtype=torch.int64, device=device)\n",
    "    }\n",
    "\n",
    "    return target_dict\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=10, device='cuda'):\n",
    "    \"\"\"Treina o modelo SSD no dataset Pascal VOC.\"\"\"\n",
    "    # Definindo dispositivo\n",
    "    device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # Definindo otimizador e scheduler\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.Adam(params, lr=0.0001)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "    # Métricas\n",
    "    results = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': []\n",
    "    }\n",
    "\n",
    "    # Loop de treinamento\n",
    "    start_time = time.time()\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nÉpoca {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        # Modo de treinamento\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        batch_count = 0\n",
    "\n",
    "        for i, (images, targets) in enumerate(train_loader):\n",
    "            # Preparar imagens e alvos para o modelo\n",
    "            images = list(img.to(device) for img in images)\n",
    "            targets_formatted = []\n",
    "            valid_images = []\n",
    "\n",
    "            for img, target in zip(images, targets):\n",
    "                target_dict = voc_to_coco_format(target, device)\n",
    "                if target_dict is not None:\n",
    "                    targets_formatted.append(target_dict)\n",
    "                    valid_images.append(img)\n",
    "\n",
    "            # Pular a iteração se não houver alvos válidos\n",
    "            if not targets_formatted:\n",
    "                continue\n",
    "\n",
    "            # Usar apenas imagens válidas\n",
    "            images = valid_images\n",
    "\n",
    "            # Zerar gradientes\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            try:\n",
    "                loss_dict = model(images, targets_formatted)\n",
    "                losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "                # Checar se a perda é válida\n",
    "                if not torch.isfinite(losses):\n",
    "                    print(f\"Perda não é finita, pulando batch {i}\")\n",
    "                    continue\n",
    "\n",
    "                # Backward pass e otimização\n",
    "                losses.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "                # Calcular perda\n",
    "                epoch_loss += losses.item()\n",
    "                batch_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Erro no batch {i}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Mostrar progresso\n",
    "            if (i + 1) % 20 == 0:\n",
    "                print(f\"  Batch {i+1}/{len(train_loader)}, Perda: {losses.item():.4f}\")\n",
    "\n",
    "        # Prevenir divisão por zero\n",
    "        if batch_count == 0:\n",
    "            print(\"Aviso: Nenhum batch válido nesta época\")\n",
    "            continue\n",
    "\n",
    "        # Salvar perda média da época\n",
    "        avg_train_loss = epoch_loss / batch_count\n",
    "        results['train_loss'].append(avg_train_loss)\n",
    "\n",
    "        # Atualizar scheduler\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        # Validação\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_batch_count = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, targets in val_loader:\n",
    "                images = list(img.to(device) for img in images)\n",
    "                targets_formatted = []\n",
    "                valid_images = []\n",
    "\n",
    "                for img, target in zip(images, targets):\n",
    "                    target_dict = voc_to_coco_format(target, device)\n",
    "                    if target_dict is not None:\n",
    "                        targets_formatted.append(target_dict)\n",
    "                        valid_images.append(img)\n",
    "\n",
    "                if not targets_formatted:\n",
    "                    continue\n",
    "\n",
    "                # Usar apenas imagens válidas\n",
    "                images = valid_images\n",
    "\n",
    "                # Forward pass - COM CORREÇÃO DO ERRO\n",
    "                try:\n",
    "                    # Em modo de avaliação, precisamos garantir que estamos no modo de treinamento para obter perdas\n",
    "                    # Temporariamente mudar para modo de treinamento para validação\n",
    "                    model.train()\n",
    "                    loss_dict = model(images, targets_formatted)\n",
    "                    model.eval()  # Voltar para modo de avaliação\n",
    "\n",
    "                    # Verificar se o resultado é um dicionário\n",
    "                    if isinstance(loss_dict, dict):\n",
    "                        losses = sum(loss for loss in loss_dict.values())\n",
    "                    elif isinstance(loss_dict, list):\n",
    "                        # Se for uma lista, estamos no modo de inferência\n",
    "                        print(\"Modelo retornou lista durante validação, passando para inferência...\")\n",
    "                        # Mudar para avaliação com targets para obter perdas\n",
    "                        model.train()\n",
    "                        loss_dict = model(images, targets_formatted)\n",
    "                        model.eval()\n",
    "                        losses = sum(loss for loss in loss_dict.values())\n",
    "                    else:\n",
    "                        print(f\"Formato inesperado durante validação: {type(loss_dict)}\")\n",
    "                        continue\n",
    "\n",
    "                    if torch.isfinite(losses):\n",
    "                        val_loss += losses.item()\n",
    "                        val_batch_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro na validação: {e}\")\n",
    "                    continue\n",
    "\n",
    "        # Calcular perda média de validação\n",
    "        if val_batch_count > 0:\n",
    "            avg_val_loss = val_loss / val_batch_count\n",
    "            results['val_loss'].append(avg_val_loss)\n",
    "\n",
    "            print(f\"  Perda de treinamento: {avg_train_loss:.4f}, Perda de validação: {avg_val_loss:.4f}\")\n",
    "\n",
    "            # Salvar o melhor modelo\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': best_val_loss,\n",
    "                }, 'best_ssdlite_mobilenet.pth')\n",
    "                print(f\"  Melhor modelo salvo (perda de validação: {best_val_loss:.4f})\")\n",
    "        else:\n",
    "            print(f\"  Perda de treinamento: {avg_train_loss:.4f}, Validação: Sem batches válidos\")\n",
    "\n",
    "    # Tempo total de treinamento\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nTreinamento completo em {total_time / 60:.2f} minutos\")\n",
    "\n",
    "    return model, results\n",
    "\n",
    "def export_to_onnx(model, device='cpu', output_path='ssdlite_mobilenet.onnx'):\n",
    "    \"\"\"Exporta o modelo treinado para o formato ONNX.\"\"\"\n",
    "    # Mover para CPU para exportação\n",
    "    model = model.to('cpu')\n",
    "    model.eval()\n",
    "\n",
    "    # Criar uma entrada de exemplo\n",
    "    dummy_input = torch.randn(1, 3, 640, 640)\n",
    "\n",
    "    # Modo de inferência para exportação\n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            # Classe wrapper para facilitar a exportação\n",
    "            class ModelWrapper(torch.nn.Module):\n",
    "                def __init__(self, model):\n",
    "                    super(ModelWrapper, self).__init__()\n",
    "                    self.model = model\n",
    "\n",
    "                def forward(self, x):\n",
    "                    # Durante a inferência, não passamos targets\n",
    "                    with torch.no_grad():\n",
    "                        return self.model([x])\n",
    "\n",
    "            # Criar wrapper\n",
    "            wrapped_model = ModelWrapper(model)\n",
    "\n",
    "            # Exportar para ONNX\n",
    "            torch.onnx.export(\n",
    "                wrapped_model,\n",
    "                dummy_input,\n",
    "                output_path,\n",
    "                export_params=True,\n",
    "                opset_version=11,\n",
    "                do_constant_folding=True,\n",
    "                input_names=['input'],\n",
    "                output_names=['detections'],\n",
    "                dynamic_axes={'input': {0: 'batch_size'}}\n",
    "            )\n",
    "\n",
    "            print(f\"Modelo exportado para {output_path}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao exportar para ONNX: {e}\")\n",
    "\n",
    "            # Tentar exportar com abordagem diferente\n",
    "            try:\n",
    "                print(\"Tentando exportação alternativa...\")\n",
    "\n",
    "                class InferenceWrapper(torch.nn.Module):\n",
    "                    def __init__(self, model):\n",
    "                        super(InferenceWrapper, self).__init__()\n",
    "                        self.model = model\n",
    "\n",
    "                    def forward(self, x):\n",
    "                        # Converter para lista antes de passar ao modelo\n",
    "                        x_list = [x]\n",
    "                        with torch.no_grad():\n",
    "                            detections = self.model(x_list)\n",
    "                        return detections\n",
    "\n",
    "                # Criar wrapper\n",
    "                inference_model = InferenceWrapper(model)\n",
    "\n",
    "                # Tentar exportar o modelo diretamente\n",
    "                torch.onnx.export(\n",
    "                    inference_model,\n",
    "                    dummy_input,\n",
    "                    \"ssdlite_mobilenet_inference.onnx\",\n",
    "                    export_params=True,\n",
    "                    opset_version=11,\n",
    "                    input_names=['input'],\n",
    "                    output_names=['output']\n",
    "                )\n",
    "                print(\"Modelo exportado com sucesso para ssdlite_mobilenet_inference.onnx\")\n",
    "                return True\n",
    "            except Exception as e2:\n",
    "                print(f\"Erro na exportação alternativa: {e2}\")\n",
    "\n",
    "                # Final fallback - exportar apenas o backbone\n",
    "                try:\n",
    "                    print(\"Tentando exportar apenas o backbone...\")\n",
    "                    backbone = model.backbone\n",
    "                    torch.onnx.export(\n",
    "                        backbone,\n",
    "                        dummy_input,\n",
    "                        \"mobilenet_backbone.onnx\",\n",
    "                        export_params=True,\n",
    "                        opset_version=11\n",
    "                    )\n",
    "                    print(\"Backbone exportado com sucesso para mobilenet_backbone.onnx\")\n",
    "                    return True\n",
    "                except Exception as e3:\n",
    "                    print(f\"Erro ao exportar backbone: {e3}\")\n",
    "                    return False\n",
    "\n",
    "def save_model_info(model, path='model_info.txt'):\n",
    "    \"\"\"Salva informações do modelo em um arquivo de texto.\"\"\"\n",
    "    info = {\n",
    "        'modelo': 'SSDLite320-MobileNetV3-Large',\n",
    "        'framework': 'PyTorch',\n",
    "        'data_treinamento': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        'dataset': 'Pascal VOC 2012',\n",
    "        'input_size': '640x640',\n",
    "        'arquitetura': str(model),\n",
    "        'num_parametros': sum(p.numel() for p in model.parameters()),\n",
    "        'parametros_treinaveis': sum(p.numel() for p in model.parameters() if p.requires_grad),\n",
    "        'versao_pytorch': torch.__version__,\n",
    "        'versao_torchvision': torchvision.__version__,\n",
    "        'classes': [\n",
    "            'background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle',\n",
    "            'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog',\n",
    "            'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa',\n",
    "            'train', 'tvmonitor'\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    with open(path, 'w') as f:\n",
    "        for key, value in info.items():\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "\n",
    "    print(f\"Informações do modelo salvas em {path}\")\n",
    "\n",
    "def main():\n",
    "    # Verificar disponibilidade de GPU\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Usando dispositivo: {device}\")\n",
    "    print(f\"Versão PyTorch: {torch.__version__}\")\n",
    "    print(f\"Versão torchvision: {torchvision.__version__}\")\n",
    "\n",
    "    # Obter datasets\n",
    "    print(\"Preparando o dataset Pascal VOC 2012 já baixado...\")\n",
    "    train_dataset, val_dataset = get_voc_dataset()\n",
    "\n",
    "    # Criar data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=16,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=16,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    # Criar modelo\n",
    "    print(\"Criando modelo SSDLite320 com MobileNetV3...\")\n",
    "    model = create_model()\n",
    "\n",
    "    # Treinar modelo\n",
    "    print(\"Iniciando treinamento...\")\n",
    "    model, results = train_model(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        num_epochs=50,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # Carregar o melhor modelo\n",
    "    try:\n",
    "        checkpoint = torch.load('best_ssdlite_mobilenet.pth', map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(f\"Melhor modelo carregado com sucesso (época {checkpoint['epoch']}).\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar o melhor modelo: {e}\")\n",
    "\n",
    "    # Exportar para ONNX\n",
    "    print(\"Exportando modelo para ONNX...\")\n",
    "    export_to_onnx(model, device)\n",
    "\n",
    "    # Salvar informações do modelo\n",
    "    print(\"Salvando informações do modelo...\")\n",
    "    save_model_info(model)\n",
    "\n",
    "    print(\"Processo concluído!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    torch.multiprocessing.set_start_method('spawn', force=True)\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edvar\\AppData\\Local\\Temp\\ipykernel_8796\\453568961.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(pth_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo exportado para best_ssdlite_mobilenet.onnx\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "# Ignora avisos de usuário (UserWarning) e avisos de tracer (TracerWarning) do PyTorch\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torchvision\")\n",
    "warnings.filterwarnings(\"ignore\", category=torch.jit.TracerWarning)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models.detection import ssdlite320_mobilenet_v3_large, SSDLite320_MobileNet_V3_Large_Weights\n",
    "\n",
    "def load_model_checkpoint(pth_path, device='cpu'):\n",
    "    # Caso queira suprimir aviso do pickle, use:\n",
    "    # checkpoint = torch.load(pth_path, map_location=device, weights_only=True)\n",
    "    checkpoint = torch.load(pth_path, map_location=device)\n",
    "    weights = SSDLite320_MobileNet_V3_Large_Weights.DEFAULT\n",
    "    model = ssdlite320_mobilenet_v3_large(weights=weights)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "class DetectionWrapper(nn.Module):\n",
    "    \"\"\"\n",
    "    Envolve o modelo SSDLite para converter tensores 4D (B,3,H,W)\n",
    "    em uma lista de (3,H,W) para cada imagem do batch.\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x é (B,3,H,W). Precisamos de [x[0], x[1], ...].\n",
    "        images = [img for img in x]\n",
    "        return self.model(images)\n",
    "\n",
    "def export_to_onnx(model, output_path=\"best_ssdlite_mobilenet.onnx\"):\n",
    "    dummy_input = torch.randn(1, 3, 640, 640)\n",
    "    wrapped_model = DetectionWrapper(model)\n",
    "    model.to('cpu')\n",
    "\n",
    "    torch.onnx.export(\n",
    "        wrapped_model,\n",
    "        dummy_input,\n",
    "        output_path,\n",
    "        export_params=True,\n",
    "        opset_version=11,\n",
    "        do_constant_folding=True,\n",
    "        input_names=['input'],\n",
    "        output_names=['detections'],\n",
    "        dynamic_axes={'input': {0: 'batch_size'}}\n",
    "    )\n",
    "    print(f\"Modelo exportado para {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = load_model_checkpoint(\"best_ssdlite_mobilenet.pth\", device=device)\n",
    "    export_to_onnx(model, \"best_ssdlite_mobilenet.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './coco/annotations/instances_train2017.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Dataset COCO\u001b[39;00m\n\u001b[32m     21\u001b[39m data_dir = \u001b[33m\"\u001b[39m\u001b[33m./coco\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# Defina o caminho correto do COCO dataset\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m dataset = \u001b[43mCocoDetection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdata_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/images/train2017\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannFile\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdata_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/annotations/instances_train2017.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m dataloader = DataLoader(dataset, batch_size=\u001b[32m4\u001b[39m, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m, collate_fn=\u001b[38;5;28;01mlambda\u001b[39;00m batch: \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mzip\u001b[39m(*batch)))\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Carregar modelo pré-treinado\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\edvar\\anaconda3\\envs\\nn\\Lib\\site-packages\\torchvision\\datasets\\coco.py:37\u001b[39m, in \u001b[36mCocoDetection.__init__\u001b[39m\u001b[34m(self, root, annFile, transform, target_transform, transforms)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(root, transforms, transform, target_transform)\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpycocotools\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcoco\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m COCO\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[38;5;28mself\u001b[39m.coco = \u001b[43mCOCO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mannFile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[38;5;28mself\u001b[39m.ids = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mself\u001b[39m.coco.imgs.keys()))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\edvar\\anaconda3\\envs\\nn\\Lib\\site-packages\\pycocotools\\coco.py:81\u001b[39m, in \u001b[36mCOCO.__init__\u001b[39m\u001b[34m(self, annotation_file)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mloading annotations into memory...\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     80\u001b[39m tic = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mannotation_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     82\u001b[39m     dataset = json.load(f)\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(dataset)==\u001b[38;5;28mdict\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mannotation file format \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m not supported\u001b[39m\u001b[33m'\u001b[39m.format(\u001b[38;5;28mtype\u001b[39m(dataset))\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './coco/annotations/instances_train2017.json'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models.detection import ssdlite320_mobilenet_v3_large\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Configuração\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Transformações para os dados\n",
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Resize((320, 320)),\n",
    "])\n",
    "\n",
    "# Dataset COCO\n",
    "data_dir = \"./coco\"  # Defina o caminho correto do COCO dataset\n",
    "dataset = CocoDetection(root=f\"{data_dir}/images/train2017\", annFile=f\"{data_dir}/annotations/instances_train2017.json\", transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=lambda batch: tuple(zip(*batch)))\n",
    "\n",
    "# Carregar modelo pré-treinado\n",
    "model = ssdlite320_mobilenet_v3_large(pretrained=True)\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "# Otimizador e critério\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "num_epochs = 5  # Ajuste conforme necessário\n",
    "\n",
    "# Treinamento\n",
    "for epoch in range(num_epochs):\n",
    "    for images, targets in dataloader:\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_dict = model(images, targets)\n",
    "        loss = sum(loss for loss in loss_dict.values())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "\n",
    "# Teste com uma imagem\n",
    "image_path = \"teste.jpg\"  # Defina a imagem de teste correta\n",
    "image = cv2.imread(image_path)\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "image_tensor = transform(image_rgb).unsqueeze(0).to(device)\n",
    "\n",
    "# Predição\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = model(image_tensor)\n",
    "\n",
    "# Desenhar bounding boxes\n",
    "image_np = image_rgb.copy()\n",
    "for box, score, label in zip(prediction[0]['boxes'], prediction[0]['scores'], prediction[0]['labels']):\n",
    "    if score > 0.5:  # Filtra objetos detectados com confiança acima de 50%\n",
    "        x1, y1, x2, y2 = map(int, box.tolist())\n",
    "        cv2.rectangle(image_np, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(image_np, f\"{label.item()} {score:.2f}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "# Exibir resultado\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image_np)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
